{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zSJqzbw1970"
   },
   "source": [
    "# Construcción de modelos de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 39844,
     "status": "ok",
     "timestamp": 1747347303739,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "BEUwy07YokUI"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1747347303754,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "ORXYGEk3jOkd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1747352915311,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "j8oMArPWjhVU",
    "outputId": "00400d64-94e4-4571-ce59-a74e96ec1180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\t  sample_data\t\t     spark-3.1.1-bin-hadoop3.2.tgz\n",
      "lr_model  spark-3.1.1-bin-hadoop3.2\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747352917391,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "rV4gjOBljnQM",
    "outputId": "8f98a3bb-8529-4460-9ce5-f7b313017e1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ff263b268738:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff8cbdf0250>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20271,
     "status": "ok",
     "timestamp": 1747347333804,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "7xHy4vM9sENW",
    "outputId": "1755bcc4-4057-4ec4-dcad-773a52d12d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747347333807,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "AL9Y9F-NsVi-"
   },
   "outputs": [],
   "source": [
    "path_file = '/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8FUiU9xZ_fI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23045,
     "status": "ok",
     "timestamp": 1747347356853,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "Oy7S8tcStCa2",
    "outputId": "6e85c192-a572-4314-f3e8-6ed04e8addf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0|  3504|        12.0|   70|    US|\n",
      "|   Buick Skylark 320|15.0|        8|       350.0|     165.0|  3693|        11.5|   70|    US|\n",
      "|  Plymouth Satellite|18.0|        8|       318.0|     150.0|  3436|        11.0|   70|    US|\n",
      "|       AMC Rebel SST|16.0|        8|       304.0|     150.0|  3433|        12.0|   70|    US|\n",
      "|         Ford Torino|17.0|        8|       302.0|     140.0|  3449|        10.5|   70|    US|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path_file, header=True, sep=\";\", inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1747347357714,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "PNkSKn5ntfL2",
    "outputId": "cf54a174-ad43-4dcc-a667-34250ffe5d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 406\n",
      "Número de columnas: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de registros: \" + str(df.count()))\n",
    "print(\"Número de columnas: \" + str(len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 2786,
     "status": "ok",
     "timestamp": 1747347360501,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "i7tdgz0x7S_b",
    "outputId": "016e5dec-606f-4cb2-ac67-421c73a0a902"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>Car</th><th>MPG</th><th>Cylinders</th><th>Displacement</th><th>Horsepower</th><th>Weight</th><th>Acceleration</th><th>Model</th><th>Origin</th></tr>\n",
       "<tr><td>count</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>23.051231527093602</td><td>5.475369458128079</td><td>194.7795566502463</td><td>103.5295566502463</td><td>2979.4138</td><td>15.519704433497521</td><td>75.92118226600985</td><td>null</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>8.4017773522706</td><td>1.712159631548529</td><td>104.92245837948867</td><td>40.52065912106347</td><td>847.0043282393513</td><td>2.8033588163425462</td><td>3.7487373454558743</td><td>null</td></tr>\n",
       "<tr><td>min</td><td>AMC Ambassador Br...</td><td>0.0</td><td>3</td><td>68.0</td><td>0.0</td><td>1613</td><td>8.0</td><td>70</td><td>Europe</td></tr>\n",
       "<tr><td>max</td><td>Volvo Diesel</td><td>46.6</td><td>8</td><td>455.0</td><td>230.0</td><td>5140</td><td>24.8</td><td>82</td><td>US</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------------+------------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------+\n",
       "|summary|                 Car|               MPG|        Cylinders|      Displacement|       Horsepower|           Weight|      Acceleration|             Model|Origin|\n",
       "+-------+--------------------+------------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------+\n",
       "|  count|                 406|               406|              406|               406|              406|              406|               406|               406|   406|\n",
       "|   mean|                null|23.051231527093602|5.475369458128079| 194.7795566502463|103.5295566502463|        2979.4138|15.519704433497521| 75.92118226600985|  null|\n",
       "| stddev|                null|   8.4017773522706|1.712159631548529|104.92245837948867|40.52065912106347|847.0043282393513|2.8033588163425462|3.7487373454558743|  null|\n",
       "|    min|AMC Ambassador Br...|               0.0|                3|              68.0|              0.0|             1613|               8.0|                70|Europe|\n",
       "|    max|        Volvo Diesel|              46.6|                8|             455.0|            230.0|             5140|              24.8|                82|    US|\n",
       "+-------+--------------------+------------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747347360516,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "bP4W9O3GKwhr",
    "outputId": "c23ac859-f2fa-4d5f-8fa9-476df5e4dd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car: string (nullable = true)\n",
      " |-- MPG: double (nullable = true)\n",
      " |-- Cylinders: integer (nullable = true)\n",
      " |-- Displacement: double (nullable = true)\n",
      " |-- Horsepower: double (nullable = true)\n",
      " |-- Weight: decimal(4,0) (nullable = true)\n",
      " |-- Acceleration: double (nullable = true)\n",
      " |-- Model: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mv6k_QP8rqJ"
   },
   "source": [
    "### Limpieza de datos\n",
    "\n",
    "El proceso de limpieza de datos depende fuertemente de las características y estado de la muestra con la cual se estará trabajando. En ocasiones, la preparación de los datos requerirá varias etapas de limpieza, transformación, eliminación de ruido, etc. en los datos, mientras que en otras ocasiones dicha preparación constará de etapas muy básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1747347360599,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "BtwWIdpvKelK"
   },
   "outputs": [],
   "source": [
    "#Se eliminan registros con valores nulos\n",
    "df_clean = df.dropna()\n",
    "\n",
    "#Se eliminan columnas con valores nulos\n",
    "df_clean = df_clean.na.drop()\n",
    "\n",
    "#Se eliminan registros duplicados\n",
    "df_clean = df_clean.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 17754,
     "status": "ok",
     "timestamp": 1747347378357,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "HpMktKygQqqd",
    "outputId": "9306db28-51b3-40fa-8fc9-0d7dd93bae23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>Car</th><th>MPG</th><th>Cylinders</th><th>Displacement</th><th>Horsepower</th><th>Weight</th><th>Acceleration</th><th>Model</th><th>Origin</th></tr>\n",
       "<tr><td>count</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td><td>406</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>23.051231527093602</td><td>5.475369458128079</td><td>194.7795566502463</td><td>103.5295566502463</td><td>2979.4138</td><td>15.519704433497537</td><td>75.92118226600985</td><td>null</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>8.401777352270594</td><td>1.7121596315485297</td><td>104.92245837948875</td><td>40.52065912106347</td><td>847.0043282393509</td><td>2.8033588163425462</td><td>3.7487373454558783</td><td>null</td></tr>\n",
       "<tr><td>min</td><td>AMC Ambassador Br...</td><td>0.0</td><td>3</td><td>68.0</td><td>0.0</td><td>1613</td><td>8.0</td><td>70</td><td>Europe</td></tr>\n",
       "<tr><td>max</td><td>Volvo Diesel</td><td>46.6</td><td>8</td><td>455.0</td><td>230.0</td><td>5140</td><td>24.8</td><td>82</td><td>US</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------+\n",
       "|summary|                 Car|               MPG|         Cylinders|      Displacement|       Horsepower|           Weight|      Acceleration|             Model|Origin|\n",
       "+-------+--------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------+\n",
       "|  count|                 406|               406|               406|               406|              406|              406|               406|               406|   406|\n",
       "|   mean|                null|23.051231527093602| 5.475369458128079| 194.7795566502463|103.5295566502463|        2979.4138|15.519704433497537| 75.92118226600985|  null|\n",
       "| stddev|                null| 8.401777352270594|1.7121596315485297|104.92245837948875|40.52065912106347|847.0043282393509|2.8033588163425462|3.7487373454558783|  null|\n",
       "|    min|AMC Ambassador Br...|               0.0|                 3|              68.0|              0.0|             1613|               8.0|                70|Europe|\n",
       "|    max|        Volvo Diesel|              46.6|                 8|             455.0|            230.0|             5140|              24.8|                82|    US|\n",
       "+-------+--------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fwBI8MLTPOw"
   },
   "source": [
    "#### Planes de transformación\n",
    "\n",
    "Es importante tomar en cuenta que al momento de implementar etapas de procesamiento en PySpark, las transformaciones no se lanzan hasta que se genera un disparador. Para ello, es fundamental crear un plan de transformación eficiente para minimizar el costo de las operaciones \"wide\".\n",
    "En este ejemplo se ordenan los registros del Dataframe, dónde el ordenamiento es una transformación \"wide\". Para visualizar el plan que aplica Spark en la transformación, se puede usar el comando \"explain\" (se lee desde arriba hacia abajo, dónde el tope es el resultado final, mientras que lo más anidado es la fuente de datos). Observemos que el plan indica \"Sort -> exchange -> FileScan\", lo que indica que es una \"wide transformation\", ya que se tienen que comparar registros de las diferentes particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4636,
     "status": "ok",
     "timestamp": 1747347382991,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "yadngCVB_IOd",
    "outputId": "fdfc310f-b0e3-447a-9eaa-bb459a60c0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [origin#24 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(origin#24 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#139]\n",
      "   +- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "      +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 200), ENSURE_REQUIREMENTS, [id=#135]\n",
      "         +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "            +- *(1) Filter AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)\n",
      "               +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Car='Volvo 144ea', MPG=19.0, Cylinders=4, Displacement=121.0, Horsepower=112.0, Weight=Decimal('2868'), Acceleration=15.5, Model=73, Origin='Europe'),\n",
       " Row(Car='Fiat Strada Custom', MPG=37.3, Cylinders=4, Displacement=91.0, Horsepower=69.0, Weight=Decimal('2130'), Acceleration=14.7, Model=79, Origin='Europe'),\n",
       " Row(Car='Volkswagen Rabbit l', MPG=36.0, Cylinders=4, Displacement=105.0, Horsepower=74.0, Weight=Decimal('1980'), Acceleration=15.3, Model=82, Origin='Europe')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#se ordenan los registros del dataframe a partir del origen\n",
    "df_clean_sort = df_clean.orderBy('origin')\n",
    "#se imprime el plan de transformaciones\n",
    "df_clean_sort.explain()\n",
    "df_clean_sort.take(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSRCJ9ylXXSH"
   },
   "source": [
    "Cuando en una transformación se involucra una \"wide transformation\", se forza a una mezcla de datos entre las diferentes particiones existentes en el cluster. Por default, Spark genera 200 particiones de mezcla, pero ello se puede controlar. Para ello se puede invocar a \"spark.conf.set\", casí como se muestra en el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1747347383726,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "cXWLmGaMXYJH",
    "outputId": "2bb92194-52b6-4e3a-d8d9-c5174c9364bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [origin#24 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(origin#24 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, [id=#199]\n",
      "   +- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "      +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 5), ENSURE_REQUIREMENTS, [id=#195]\n",
      "         +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "            +- *(1) Filter AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)\n",
      "               +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Car='Fiat 124B', MPG=30.0, Cylinders=4, Displacement=88.0, Horsepower=76.0, Weight=Decimal('2065'), Acceleration=14.5, Model=71, Origin='Europe'),\n",
       " Row(Car='Fiat 128', MPG=29.0, Cylinders=4, Displacement=68.0, Horsepower=49.0, Weight=Decimal('1867'), Acceleration=19.5, Model=73, Origin='Europe'),\n",
       " Row(Car='Volkswagen 411 (sw)', MPG=22.0, Cylinders=4, Displacement=121.0, Horsepower=76.0, Weight=Decimal('2511'), Acceleration=18.0, Model=72, Origin='Europe')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")\n",
    "\n",
    "df_clean_sort = df_clean.orderBy('origin')\n",
    "#se imprime el plan de transformaciones\n",
    "df_clean_sort.explain()\n",
    "df_clean_sort.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1747347384260,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "mqEPxxGOZVnp",
    "outputId": "9b45d5a3-3372-45c2-c45f-d985f2838fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "|           Fiat 124B|30.0|        4|        88.0|      76.0|  2065|        14.5|   71|Europe|\n",
      "|            Fiat 128|24.0|        4|        90.0|      75.0|  2108|        15.5|   74|Europe|\n",
      "|Citroen DS-21 Pallas| 0.0|        4|       133.0|     115.0|  3090|        17.5|   70|Europe|\n",
      "|Volkswagen 1131 D...|26.0|        4|        97.0|      46.0|  1835|        20.5|   70|Europe|\n",
      "| Volkswagen 411 (sw)|22.0|        4|       121.0|      76.0|  2511|        18.0|   72|Europe|\n",
      "|            Fiat 128|29.0|        4|        68.0|      49.0|  1867|        19.5|   73|Europe|\n",
      "|          Opel Manta|24.0|        4|       116.0|      75.0|  2158|        15.5|   73|Europe|\n",
      "|         Volvo 144ea|19.0|        4|       121.0|     112.0|  2868|        15.5|   73|Europe|\n",
      "|           Saab 99le|24.0|        4|       121.0|     110.0|  2660|        14.0|   73|Europe|\n",
      "|            Audi Fox|29.0|        4|        98.0|      83.0|  2219|        16.5|   74|Europe|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean_sort.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbbckfrjXuK8"
   },
   "source": [
    "Definido un plan lógico de transformaciones, Spark sabe como aplicar dicho plan a las particiones que se estén trabajando, con lo que si se vuelva a aplicar dicho plan a los mismos datos de entrada, se obtendrá el mismo resultado (programación funcional, donde las mismas entradas dan las mismas salidas siempre y cuando las transformaciones sobre esos datos permanezcan constantes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHpml86cYYHt"
   },
   "source": [
    "#### Manipulación a través de SQL\n",
    "\n",
    "Se pueden definir las transformaciones a través del lenguaje de consulta SQL. Cuando se definen las transformaciones a través de SQL, Spark compilará el plan de acción antes de su ejecución. Para ello, primero se debe de registrar un Dataframe como una tabla o vista (view), con lo cual se pueden armar las consultas SQL puro. En principio, no existe diferencia entre consultas SQL y su equivalente en operadores nativos de Dataframes Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1747347384672,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "CpnVKuxlY8qr"
   },
   "outputs": [],
   "source": [
    "df_clean_sort.createOrReplaceTempView(\"cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upZCgQceZCyH"
   },
   "source": [
    "Ahora ya se pueden definir consultas en SQL, dónde las salidas serán Dataframes de Spark. A continuación se muestran dos planes de acción, una definida con SQL y la otra a través de comandos nativos de Dataframes de Spark, y se usa explain() para visualizar el plan de acción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1747347386224,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "rbxpN1LRZM4a",
    "outputId": "13e92d12-bbd7-4e04-d665-216d78da1ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) HashAggregate(keys=[Origin#24], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(Origin#24, 5), ENSURE_REQUIREMENTS, [id=#294]\n",
      "   +- *(2) HashAggregate(keys=[Origin#24], functions=[partial_count(1)])\n",
      "      +- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "         +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 5), ENSURE_REQUIREMENTS, [id=#289]\n",
      "            +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "               +- *(1) Filter AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)\n",
      "                  +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) HashAggregate(keys=[Origin#24], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(Origin#24, 5), ENSURE_REQUIREMENTS, [id=#332]\n",
      "   +- *(2) HashAggregate(keys=[Origin#24], functions=[partial_count(1)])\n",
      "      +- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "         +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 5), ENSURE_REQUIREMENTS, [id=#327]\n",
      "            +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "               +- *(1) Filter AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)\n",
      "                  +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n",
      "+------+--------+\n",
      "|Origin|count(1)|\n",
      "+------+--------+\n",
      "| Japan|      79|\n",
      "|    US|     254|\n",
      "|Europe|      73|\n",
      "+------+--------+\n",
      "\n",
      "+------+-----+\n",
      "|Origin|count|\n",
      "+------+-----+\n",
      "| Japan|   79|\n",
      "|    US|  254|\n",
      "|Europe|   73|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT Origin, count(1) FROM cars GROUP BY Origin\"\"\"\n",
    "df_sql = spark.sql(query)\n",
    "df_sql.explain()\n",
    "\n",
    "df_nosql = df_clean_sort.groupBy('Origin').count()\n",
    "df_nosql.explain()\n",
    "\n",
    "df_sql.show(5)\n",
    "df_nosql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1747347386469,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "0UT8SC9YcPXg",
    "outputId": "dc9893d6-614e-4022-f0ba-71c25e59fab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=5, orderBy=[MPG#17 DESC NULLS LAST], output=[Car#16])\n",
      "+- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "   +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 5), ENSURE_REQUIREMENTS, [id=#449]\n",
      "      +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "         +- *(1) Filter ((isnotnull(Origin#24) AND AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)) AND (Origin#24 = Japan))\n",
      "            +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [isnotnull(Origin#24), AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Origin), EqualTo(Origin,Japan)], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# obtener los carros con mayor MPG de origen japones\n",
    "\n",
    "query_japan_cars = \"\"\"\n",
    "                  SELECT Car FROM cars\n",
    "                  WHERE Origin = 'Japan'\n",
    "                  ORDER BY MPG DESC\n",
    "                  LIMIT 5\n",
    "                  \"\"\"\n",
    "df_japan_cars_best_mpg = spark.sql(query_japan_cars)\n",
    "df_japan_cars_best_mpg.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1747347386581,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "Q2KleY4yd9RJ",
    "outputId": "74f9b9c3-bd16-4109-a206-20f1f6d46ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=5, orderBy=[MPG#17 DESC NULLS LAST], output=[Car#16])\n",
      "+- *(2) HashAggregate(keys=[Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16], functions=[])\n",
      "   +- Exchange hashpartitioning(Cylinders#18, Horsepower#20, Origin#24, Weight#21, Model#23, MPG#17, Acceleration#22, Displacement#19, Car#16, 5), ENSURE_REQUIREMENTS, [id=#481]\n",
      "      +- *(1) HashAggregate(keys=[Cylinders#18, knownfloatingpointnormalized(normalizenanandzero(Horsepower#20)) AS Horsepower#20, Origin#24, Weight#21, Model#23, knownfloatingpointnormalized(normalizenanandzero(MPG#17)) AS MPG#17, knownfloatingpointnormalized(normalizenanandzero(Acceleration#22)) AS Acceleration#22, knownfloatingpointnormalized(normalizenanandzero(Displacement#19)) AS Displacement#19, Car#16], functions=[])\n",
      "         +- *(1) Filter ((isnotnull(Origin#24) AND AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24)) AND (Origin#24 = Japan))\n",
      "            +- FileScan csv [Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,Weight#21,Acceleration#22,Model#23,Origin#24] Batched: false, DataFilters: [isnotnull(Origin#24), AtLeastNNulls(n, Car#16,MPG#17,Cylinders#18,Displacement#19,Horsepower#20,..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/cars.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Origin), EqualTo(Origin,Japan)], ReadSchema: struct<Car:string,MPG:double,Cylinders:int,Displacement:double,Horsepower:double,Weight:decimal(4...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# misma consulta con operadores PySpark\n",
    "\n",
    "df_japan_cars_best_mpg2 = df_clean_sort.filter(df_clean_sort.Origin == 'Japan')\\\n",
    "                                       .orderBy(df_clean_sort.MPG, ascending=False)\\\n",
    "                                       .select('Car')\\\n",
    "                                       .limit(5)\n",
    "\n",
    "df_japan_cars_best_mpg2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1747347387374,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "cLHhNAq-hCvH",
    "outputId": "e4503a28-70a7-4782-d42b-bdb87d7facea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                Car|\n",
      "+-------------------+\n",
      "|          Mazda GLC|\n",
      "|Honda Civic 1500 gl|\n",
      "|         Datsun 210|\n",
      "|     Datsun B210 GX|\n",
      "|     Toyota Starlet|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|                Car|\n",
      "+-------------------+\n",
      "|          Mazda GLC|\n",
      "|Honda Civic 1500 gl|\n",
      "|         Datsun 210|\n",
      "|     Datsun B210 GX|\n",
      "|     Toyota Starlet|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_japan_cars_best_mpg.show(5)\n",
    "df_japan_cars_best_mpg2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdMxO6HKk7fS"
   },
   "source": [
    "# Aprendizaje máquina\n",
    "\n",
    "Dentro de la Inteligencia Artificial, el aprendizaje máquina (Machine Learning o ML) se enfoca en el estudio y diseño de algoritmos que permiten procesar una serie de datos para encontrar tendencias, patrones ocultos en los datos, construyendo modelos de aprendizaje. Existen diferentes tipos de aprendizaje, como lo es el parendizaje supervisado, no supervisado o por refuerzo.\n",
    "\n",
    "El aprendizaje supervisado se parte de una colección de datos previamente etiquetados (significado semántico), denominado valor de clase, a partir de los cuales se trata de construir modelos que puedan predecir el valor de clase a partir de una nueva instancia no etiquetada. Los valores de clase pueden ser de dos tipos, discretos y continuos, lo que deriva en los dos tipos de aprendizaje supervisado: clasificación y regresión.\n",
    "\n",
    "Por otro lado, en el parendizaje no supervisado se parte de un conjunto de datos no etiquetados (se desconoce el valor de clase de las instancias). Por lo tanto, en lugar de construir modelos para predevir un valor de clase, el aprendizaje no supervisado construye modelos que ayudan a entender la estructura de los datos en un hiper-espacio (nubes de datos o clusters). Este tipo de aprendizaje es muy útil para tareas como la identificación de valores atípicos (outliers), o como etapa previa (preprocesamiento) del aprendizaje supervisado (a los grupos identificados se les asigna un valor de clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLfjty1AulGT"
   },
   "source": [
    "#### Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9czJiVDsv1Uj"
   },
   "source": [
    "Para el ejemplo, se estará usaudon la base de datos de BostonHousing ([link](https://www.kaggle.com/datasets/altavish/boston-housing-dataset/data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1489,
     "status": "ok",
     "timestamp": 1747347388926,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "Jm-xA1ePwWXv",
    "outputId": "8a6dd913-1446-4e08-9e09-60178b7582cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Número de registros: 506\n",
      "Número de columnas: 14\n"
     ]
    }
   ],
   "source": [
    "path_file = '/content/drive/MyDrive/BigData_Maestria/Clase/BostonHousing.csv'\n",
    "df = spark.read.csv(path_file, header=True, sep=\",\", inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"Número de registros: \" + str(df.count()))\n",
    "print(\"Número de columnas: \" + str(len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1747347388980,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "jbA3_ZeUwzfA",
    "outputId": "ec8a2538-af62-478e-8aa0-a39b7c75b9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- crim: double (nullable = true)\n",
      " |-- zn: double (nullable = true)\n",
      " |-- indus: double (nullable = true)\n",
      " |-- chas: integer (nullable = true)\n",
      " |-- nox: double (nullable = true)\n",
      " |-- rm: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- dis: double (nullable = true)\n",
      " |-- rad: integer (nullable = true)\n",
      " |-- tax: integer (nullable = true)\n",
      " |-- ptratio: double (nullable = true)\n",
      " |-- black: double (nullable = true)\n",
      " |-- lstat: double (nullable = true)\n",
      " |-- medv: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1747347389849,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "gcVQ1QrVxGBl",
    "outputId": "04098905-7996-46ea-e860-0ecf2c9df231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400], functions=[])\n",
      "+- Exchange hashpartitioning(rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400, 5), ENSURE_REQUIREMENTS, [id=#618]\n",
      "   +- *(1) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, knownfloatingpointnormalized(normalizenanandzero(medv#1412)) AS medv#1412, knownfloatingpointnormalized(normalizenanandzero(rm#1404)) AS rm#1404, knownfloatingpointnormalized(normalizenanandzero(age#1405)) AS age#1405, knownfloatingpointnormalized(normalizenanandzero(ptratio#1409)) AS ptratio#1409, knownfloatingpointnormalized(normalizenanandzero(black#1410)) AS black#1410, knownfloatingpointnormalized(normalizenanandzero(nox#1403)) AS nox#1403, knownfloatingpointnormalized(normalizenanandzero(crim#1399)) AS crim#1399, knownfloatingpointnormalized(normalizenanandzero(indus#1401)) AS indus#1401, knownfloatingpointnormalized(normalizenanandzero(lstat#1411)) AS lstat#1411, knownfloatingpointnormalized(normalizenanandzero(dis#1406)) AS dis#1406, knownfloatingpointnormalized(normalizenanandzero(zn#1400)) AS zn#1400], functions=[])\n",
      "      +- *(1) Filter AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412)\n",
      "         +- FileScan csv [crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412] Batched: false, DataFilters: [AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/BostonHousing.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<crim:double,zn:double,indus:double,chas:int,nox:double,rm:double,age:double,dis:double,rad...\n",
      "\n",
      "\n",
      "+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim| zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.03237|0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905|0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "|0.62976|0.0| 8.14|   0|0.538|5.949|61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.84054|0.0| 8.14|   0|0.538|5.599|85.7|4.4546|  4|307|   21.0|303.42|16.51|13.9|\n",
      "|0.95577|0.0| 8.14|   0|0.538|6.047|88.8|4.4534|  4|307|   21.0|306.38|17.28|14.8|\n",
      "+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Número de registros: 506\n",
      "Número de columnas: 14\n"
     ]
    }
   ],
   "source": [
    "# Limpieza básica de datos\n",
    "#Se eliminan registros con valores nulos\n",
    "df_clean = df.dropna()\n",
    "\n",
    "#Se eliminan registros duplicados\n",
    "df_clean= df_clean.dropDuplicates()\n",
    "\n",
    "df_clean.explain()\n",
    "df_clean.show(5)\n",
    "\n",
    "print(\"Número de registros: \" + str(df_clean.count()))\n",
    "print(\"Número de columnas: \" + str(len(df_clean.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6MomFtRyyXK"
   },
   "source": [
    "El conjunto de datos de entrada, se tiene que dividir en subconjuntos para el proceso de entrenamiento: train, validation, test. En muchos casos, el particionamiento se realiza generando únicamente el train y test, usando para ello porcentajes de particionamiento típico 80-20, 70-30, a partir de un muestreo aleatorio simple.\n",
    "\n",
    "Sin embargo, es Big Data es crucial preparar cuidadosamente dichos conjuntos, ya que la construcción de modelos es computacionalmente cara. Por ello, es preferible usar una estrategia de muestreo que garantice la representatividad de los diversos comportamientos que tienen los datos, para evitar sesgos de representatividad en los conjuntos train y test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9245,
     "status": "ok",
     "timestamp": 1747347402529,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "4vxonUv7yqSi",
    "outputId": "83dd60d9-51c3-4ec8-8146-b135d7182eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 410 instancias en el conjunto train, y 96 en el conjunto test\n"
     ]
    }
   ],
   "source": [
    "# Particionamiento típico\n",
    "# Se define el valor por default del número de ejecutores\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "train_data,test_data = df_clean.randomSplit([0.8,0.2], seed = 42)\n",
    "print(f\"\"\"Existen {train_data.count()} instancias en el conjunto train, y {test_data.count()} en el conjunto test\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1747347404096,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "42m-rBYb1M7I",
    "outputId": "f9144bac-4847-45a3-dbb0-05d8e63695f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sample 0.0, 0.8, false, 42\n",
      "+- *(2) Sort [crim#1399 ASC NULLS FIRST, zn#1400 ASC NULLS FIRST, indus#1401 ASC NULLS FIRST, chas#1402 ASC NULLS FIRST, nox#1403 ASC NULLS FIRST, rm#1404 ASC NULLS FIRST, age#1405 ASC NULLS FIRST, dis#1406 ASC NULLS FIRST, rad#1407 ASC NULLS FIRST, tax#1408 ASC NULLS FIRST, ptratio#1409 ASC NULLS FIRST, black#1410 ASC NULLS FIRST, lstat#1411 ASC NULLS FIRST, medv#1412 ASC NULLS FIRST], false, 0\n",
      "   +- *(2) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400], functions=[])\n",
      "      +- Exchange hashpartitioning(rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400, 200), ENSURE_REQUIREMENTS, [id=#827]\n",
      "         +- *(1) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, knownfloatingpointnormalized(normalizenanandzero(medv#1412)) AS medv#1412, knownfloatingpointnormalized(normalizenanandzero(rm#1404)) AS rm#1404, knownfloatingpointnormalized(normalizenanandzero(age#1405)) AS age#1405, knownfloatingpointnormalized(normalizenanandzero(ptratio#1409)) AS ptratio#1409, knownfloatingpointnormalized(normalizenanandzero(black#1410)) AS black#1410, knownfloatingpointnormalized(normalizenanandzero(nox#1403)) AS nox#1403, knownfloatingpointnormalized(normalizenanandzero(crim#1399)) AS crim#1399, knownfloatingpointnormalized(normalizenanandzero(indus#1401)) AS indus#1401, knownfloatingpointnormalized(normalizenanandzero(lstat#1411)) AS lstat#1411, knownfloatingpointnormalized(normalizenanandzero(dis#1406)) AS dis#1406, knownfloatingpointnormalized(normalizenanandzero(zn#1400)) AS zn#1400], functions=[])\n",
      "            +- *(1) Filter AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412)\n",
      "               +- FileScan csv [crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412] Batched: false, DataFilters: [AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/BostonHousing.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<crim:double,zn:double,indus:double,chas:int,nox:double,rm:double,age:double,dis:double,rad...\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Sample 0.8, 1.0, false, 42\n",
      "+- *(2) Sort [crim#1399 ASC NULLS FIRST, zn#1400 ASC NULLS FIRST, indus#1401 ASC NULLS FIRST, chas#1402 ASC NULLS FIRST, nox#1403 ASC NULLS FIRST, rm#1404 ASC NULLS FIRST, age#1405 ASC NULLS FIRST, dis#1406 ASC NULLS FIRST, rad#1407 ASC NULLS FIRST, tax#1408 ASC NULLS FIRST, ptratio#1409 ASC NULLS FIRST, black#1410 ASC NULLS FIRST, lstat#1411 ASC NULLS FIRST, medv#1412 ASC NULLS FIRST], false, 0\n",
      "   +- *(2) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400], functions=[])\n",
      "      +- Exchange hashpartitioning(rad#1407, tax#1408, chas#1402, medv#1412, rm#1404, age#1405, ptratio#1409, black#1410, nox#1403, crim#1399, indus#1401, lstat#1411, dis#1406, zn#1400, 200), ENSURE_REQUIREMENTS, [id=#861]\n",
      "         +- *(1) HashAggregate(keys=[rad#1407, tax#1408, chas#1402, knownfloatingpointnormalized(normalizenanandzero(medv#1412)) AS medv#1412, knownfloatingpointnormalized(normalizenanandzero(rm#1404)) AS rm#1404, knownfloatingpointnormalized(normalizenanandzero(age#1405)) AS age#1405, knownfloatingpointnormalized(normalizenanandzero(ptratio#1409)) AS ptratio#1409, knownfloatingpointnormalized(normalizenanandzero(black#1410)) AS black#1410, knownfloatingpointnormalized(normalizenanandzero(nox#1403)) AS nox#1403, knownfloatingpointnormalized(normalizenanandzero(crim#1399)) AS crim#1399, knownfloatingpointnormalized(normalizenanandzero(indus#1401)) AS indus#1401, knownfloatingpointnormalized(normalizenanandzero(lstat#1411)) AS lstat#1411, knownfloatingpointnormalized(normalizenanandzero(dis#1406)) AS dis#1406, knownfloatingpointnormalized(normalizenanandzero(zn#1400)) AS zn#1400], functions=[])\n",
      "            +- *(1) Filter AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412)\n",
      "               +- FileScan csv [crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1407,tax#1408,ptratio#1409,black#1410,lstat#1411,medv#1412] Batched: false, DataFilters: [AtLeastNNulls(n, crim#1399,zn#1400,indus#1401,chas#1402,nox#1403,rm#1404,age#1405,dis#1406,rad#1..., Format: CSV, Location: InMemoryFileIndex[file:/content/drive/MyDrive/BigData_Maestria/Clase/BostonHousing.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<crim:double,zn:double,indus:double,chas:int,nox:double,rm:double,age:double,dis:double,rad...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt: imprimir el plan de transformación al llamar randomSplit\n",
    "\n",
    "train_data.explain()\n",
    "test_data.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1843,
     "status": "ok",
     "timestamp": 1747347410944,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "N-OrxF2k1_Ej",
    "outputId": "b48e0f25-cd06-463a-82d2-b67b47c8dc76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+------+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|   nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+------+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.62976| 0.0| 8.14|   0| 0.538|5.949|61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.06899| 0.0|25.65|   0| 0.581| 5.87|69.7|2.2577|  2|188|   19.1|389.15|14.37|22.0|\n",
      "|0.03578|20.0| 3.33|   0|0.4429| 7.82|64.5|4.6947|  5|216|   14.9|387.31| 3.76|45.4|\n",
      "|0.03961| 0.0| 5.19|   0| 0.515|6.037|34.5|5.9853|  5|224|   20.2| 396.9| 8.01|21.1|\n",
      "|0.05372| 0.0|13.92|   0| 0.437|6.549|51.0|5.9604|  4|289|   16.0|392.85| 7.39|27.1|\n",
      "+-------+----+-----+----+------+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.22188|20.0| 6.96|   1|0.464|7.691|51.8|4.3665|  3|223|   18.6|390.77| 6.58|35.2|\n",
      "|0.97617| 0.0|21.89|   0|0.624|5.757|98.4| 2.346|  4|437|   21.2|262.76|17.31|15.6|\n",
      "|0.07022| 0.0| 4.05|   0| 0.51| 6.02|47.2|3.5549|  5|296|   16.6|393.23|10.11|23.2|\n",
      "|0.09849| 0.0|25.65|   0|0.581|5.879|95.8|2.0063|  2|188|   19.1|379.38|17.58|18.8|\n",
      "|0.52014|20.0| 3.97|   0|0.647|8.398|91.5|2.2885|  5|264|   13.0|386.86| 5.91|48.8|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se imprime algunos registros del train y test generado\n",
    "train_data.show(5)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqR_5JUP2mYI"
   },
   "source": [
    "Pero, ¿qué sucede si cambiamos el número de ejecutores en nuestro clúster de Spark? El optimizador Catalyst determina la forma óptima de particionar tus datos en función de los recursos de tu clúster y el tamaño de tu conjunto de datos. Dado que los datos en un DataFrame de Spark están particionados por filas y cada trabajador realiza su división independientemente de los demás trabajadores, si los datos en las particiones cambian, entonces el resultado de la división (por randomSplit()) no será el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1747347413823,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "BnJbd16A2wAW",
    "outputId": "032812ca-34f2-4136-b0c1-8fea595b37cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 430 instancias en el conjunto train, y 76 en el conjunto test\n"
     ]
    }
   ],
   "source": [
    "# Se define el valor por default del número de ejecutores\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "train_data,test_data = df_clean.randomSplit([0.8,0.2], seed = 42)\n",
    "print(f\"\"\"Existen {train_data.count()} instancias en el conjunto train, y {test_data.count()} en el conjunto test\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1747347415565,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "QfDt8rx22-jq",
    "outputId": "96f6be96-ecdd-4f77-e5b0-38f4f25366d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.00906|90.0| 2.97|   0|  0.4|7.088|20.8|7.3073|  1|285|   15.3|394.72| 7.85|32.2|\n",
      "|0.01301|35.0| 1.52|   0|0.442|7.241|49.3|7.0379|  1|284|   15.5|394.74| 5.49|32.7|\n",
      "|0.01311|90.0| 1.22|   0|0.403|7.249|21.9|8.6966|  5|226|   17.9|395.93| 4.81|35.4|\n",
      "| 0.0136|75.0|  4.0|   0| 0.41|5.888|47.6|7.3197|  3|469|   21.1| 396.9| 14.8|18.9|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.01096|55.0| 2.25|   0|0.389|6.453|31.9|7.3073|  1|300|   15.3|394.72| 8.23|22.0|\n",
      "|0.01381|80.0| 0.46|   0|0.422|7.875|32.0|5.6484|  4|255|   14.4|394.23| 2.97|50.0|\n",
      "|0.01439|60.0| 2.93|   0|0.401|6.604|18.8|6.2196|  1|265|   15.6| 376.7| 4.38|29.1|\n",
      "|0.01778|95.0| 1.47|   0|0.403|7.135|13.9|7.6534|  3|402|   17.0| 384.3| 4.45|32.9|\n",
      "|0.02177|82.5| 2.03|   0|0.415| 7.61|15.7|  6.27|  2|348|   14.7|395.38| 3.11|42.3|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se imprime algunos registros del train y test generado\n",
    "train_data.show(5)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGLpFgAd3Cpz"
   },
   "source": [
    "En principio, si los conjuntos train y test son de calidad (representativos), el modelo que se construya a partir de estos datos debría ser idelamente \"idéntico\". Sin embargo, en la práctica suelen haber variaciones, lo que no es deseable si se esta trabajando con grándes volumenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp8dNpHcOVbA"
   },
   "source": [
    "#### Ejemplo de muestreo estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "executionInfo": {
     "elapsed": 1433,
     "status": "ok",
     "timestamp": 1747347458965,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "wcVj02IW5z8I",
    "outputId": "d02c7e65-f41d-437c-e05c-5a09f6f18bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>crim</th><th>zn</th><th>indus</th><th>chas</th><th>nox</th><th>rm</th><th>age</th><th>dis</th><th>rad</th><th>tax</th><th>ptratio</th><th>black</th><th>lstat</th><th>medv</th></tr>\n",
       "<tr><td>count</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td><td>506</td></tr>\n",
       "<tr><td>mean</td><td>3.6135235573122535</td><td>11.363636363636363</td><td>11.136778656126504</td><td>0.0691699604743083</td><td>0.5546950592885372</td><td>6.284634387351787</td><td>68.57490118577078</td><td>3.795042687747034</td><td>9.549407114624506</td><td>408.2371541501976</td><td>18.455533596837967</td><td>356.67403162055257</td><td>12.653063241106723</td><td>22.532806324110698</td></tr>\n",
       "<tr><td>stddev</td><td>8.601545105332491</td><td>23.32245299451514</td><td>6.860352940897589</td><td>0.2539940413404101</td><td>0.11587767566755584</td><td>0.7026171434153232</td><td>28.148861406903595</td><td>2.10571012662761</td><td>8.707259384239366</td><td>168.53711605495903</td><td>2.1649455237144455</td><td>91.29486438415782</td><td>7.141061511348571</td><td>9.197104087379815</td></tr>\n",
       "<tr><td>min</td><td>0.00632</td><td>0.0</td><td>0.46</td><td>0</td><td>0.385</td><td>3.561</td><td>2.9</td><td>1.1296</td><td>1</td><td>187</td><td>12.6</td><td>0.32</td><td>1.73</td><td>5.0</td></tr>\n",
       "<tr><td>max</td><td>88.9762</td><td>100.0</td><td>27.74</td><td>1</td><td>0.871</td><td>8.78</td><td>100.0</td><td>12.1265</td><td>24</td><td>711</td><td>22.0</td><td>396.9</td><td>37.97</td><td>50.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
       "|summary|              crim|                zn|             indus|              chas|                nox|                rm|               age|              dis|              rad|               tax|           ptratio|             black|             lstat|              medv|\n",
       "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
       "|  count|               506|               506|               506|               506|                506|               506|               506|              506|              506|               506|               506|               506|               506|               506|\n",
       "|   mean|3.6135235573122535|11.363636363636363|11.136778656126504|0.0691699604743083| 0.5546950592885372| 6.284634387351787| 68.57490118577078|3.795042687747034|9.549407114624506| 408.2371541501976|18.455533596837967|356.67403162055257|12.653063241106723|22.532806324110698|\n",
       "| stddev| 8.601545105332491| 23.32245299451514| 6.860352940897589|0.2539940413404101|0.11587767566755584|0.7026171434153232|28.148861406903595| 2.10571012662761|8.707259384239366|168.53711605495903|2.1649455237144455| 91.29486438415782| 7.141061511348571| 9.197104087379815|\n",
       "|    min|           0.00632|               0.0|              0.46|                 0|              0.385|             3.561|               2.9|           1.1296|                1|               187|              12.6|              0.32|              1.73|               5.0|\n",
       "|    max|           88.9762|             100.0|             27.74|                 1|              0.871|              8.78|             100.0|          12.1265|               24|               711|              22.0|             396.9|             37.97|              50.0|\n",
       "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1747347464264,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "EC9XDRevElJa",
    "outputId": "7a533903-d9da-4a8d-8d9c-c583d12a55a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 506\n",
      "Número de columnas: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de registros: \" + str(df_clean.count()))\n",
    "print(\"Número de columnas: \" + str(len(df_clean.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1623,
     "status": "ok",
     "timestamp": 1747347466498,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "AB9CFMWdGozr",
    "outputId": "ebcfaf50-13c2-4574-dffe-a1fafa1398f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+-----------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm|  age|   dis|rad|tax|ptratio| black|lstat|medv|medv_binned|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+-----------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|        1.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|        1.0|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|        1.0|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|        1.0|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|        1.0|\n",
      "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|        1.0|\n",
      "|0.08829|12.5| 7.87|   0|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|        1.0|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|        1.0|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|        0.0|\n",
      "|0.17004|12.5| 7.87|   0|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|        0.0|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|        0.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|        0.0|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|        1.0|\n",
      "|0.62976| 0.0| 8.14|   0|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|        0.0|\n",
      "|0.63796| 0.0| 8.14|   0|0.538|6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26|18.2|        0.0|\n",
      "|0.62739| 0.0| 8.14|   0|0.538|5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|        0.0|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|        1.0|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|        0.0|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|        0.0|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|        0.0|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Número de registros: 506\n",
      "Número de columnas: 15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\n",
    "# Se calcula el valor de discretización a partir del número de bins. El resultado se almacena en \"medv_binned\"\n",
    "num_bins = 2\n",
    "quantile_discretizer = QuantileDiscretizer(numBuckets=num_bins, inputCol=\"medv\", outputCol=\"medv_binned\")\n",
    "\n",
    "# Aplicar transformación\n",
    "df_clean_bin = quantile_discretizer.fit(df_clean).transform(df_clean)\n",
    "\n",
    "df_clean_bin.show()\n",
    "print(\"Número de registros: \" + str(df_clean_bin.count()))\n",
    "print(\"Número de columnas: \" + str(len(df_clean_bin.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1747347469965,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "5TnsJ5un9bvl",
    "outputId": "17775886-a6db-4ecd-e3de-4f821fee61ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(medv_binned=1.0, count=255), Row(medv_binned=0.0, count=251)]\n",
      "506\n"
     ]
    }
   ],
   "source": [
    "# Se obtiene el número de instancias por bin\n",
    "stratum_counts = df_clean_bin.groupBy(\"medv_binned\").count().collect()\n",
    "total_count = df_clean_bin.count()\n",
    "\n",
    "print(stratum_counts)\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747348693254,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "ybQBJERrArOJ",
    "outputId": "e21c96cb-982e-45ed-9b13-79de0315ac83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 0.15118577075098813, 0.0: 0.14881422924901186}\n"
     ]
    }
   ],
   "source": [
    "# Se calcula la probabilidad del test de cada bin de acuerdo al porcentaje de division a usar (70 - 30)\n",
    "\n",
    "stratum_fractions = {row[\"medv_binned\"]: 0.3 * (row[\"count\"] / total_count)\n",
    "                     for row in stratum_counts}\n",
    "\n",
    "print(stratum_fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3924,
     "status": "ok",
     "timestamp": 1747348698075,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "L0413LVYCHH0",
    "outputId": "90f7b2df-2d7a-4a25-ad2a-3ed37520d22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 435 instancias en el conjunto train, y 71 en el conjunto test\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|medv_binned|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|        1.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|        1.0|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|        1.0|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|        1.0|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|        1.0|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|medv_binned|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172|96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|        1.0|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935|29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|        1.0|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456|36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|        0.0|\n",
      "|0.25387| 0.0| 6.91|   0|0.448|5.399|95.3|  5.87|  3|233|   17.9| 396.9|30.81|14.4|        0.0|\n",
      "|0.08873|21.0| 5.64|   0|0.439|5.963|45.7|6.8147|  4|243|   16.8|395.56|13.45|19.7|        0.0|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se generan los conjuntos a partir de muestreo estratificado\n",
    "test_data = df_clean_bin.sampleBy(\"medv_binned\", fractions=stratum_fractions, seed=42)\n",
    "train_data = df_clean_bin.exceptAll(test_data)\n",
    "\n",
    "print(f\"\"\"Existen {train_data.count()} instancias en el conjunto train, y {test_data.count()} en el conjunto test\"\"\")\n",
    "\n",
    "train_data.show(5)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffMZzmpZTEm_"
   },
   "source": [
    "#### Preparación del dataframe para ser procesado con algoritmos de ML en PySpark\n",
    "\n",
    "Se usa VectorAssembler para generar una o más columnas en la cual, se \"encapuslan\" en un vector único los valores de los descriptores a usar en el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1747348702146,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "kLbRqmK9TL6G",
    "outputId": "af8d546c-0685-4c3d-c241-413497a45df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|medv_binned|          Attributes|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|        1.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|        1.0|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|        1.0|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|        1.0|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|        1.0|[0.06905,0.0,2.18...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|medv|medv_binned|          Attributes|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172|96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|        1.0|[0.14455,12.5,7.8...|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935|29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|        1.0|[1.05393,0.0,8.14...|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456|36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|        0.0|[0.80271,0.0,8.14...|\n",
      "|0.25387| 0.0| 6.91|   0|0.448|5.399|95.3|  5.87|  3|233|   17.9| 396.9|30.81|14.4|        0.0|[0.25387,0.0,6.91...|\n",
      "|0.08873|21.0| 5.64|   0|0.439|5.963|45.7|6.8147|  4|243|   16.8|395.56|13.45|19.7|        0.0|[0.08873,21.0,5.6...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat'], outputCol = 'Attributes')\n",
    "output_train = assembler.transform(train_data)\n",
    "output_test = assembler.transform(test_data)\n",
    "\n",
    "output_train.show(5)\n",
    "output_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9V6DBTGXJDg"
   },
   "source": [
    "#### Ejemplo de Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 2654,
     "status": "ok",
     "timestamp": 1747348706634,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "Noy2YAsYTwwT"
   },
   "outputs": [],
   "source": [
    "# Se manda a entrenar con un modelo de regresion Lineal\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(output_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1747348706699,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "SHj1BS-BVK8D",
    "outputId": "5ea72edf-6309-4cd0-90a6-bc93df93be0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of the model is :  [-0.031034601210892566,0.01802274847148352,-0.022315059672006466,2.0062887531369724,-7.172130109899271,4.031876007066287,0.0,-0.7300192446759362,0.0,0.0,-0.761627024488328,0.007644093273434244,-0.564161432039539]\n",
      "The Intercept of the model is :  22.531404042417087\n"
     ]
    }
   ],
   "source": [
    "# Se Imprimen los valores de los coeficientes\n",
    "print (\"The coefficient of the model is : \", lr_model.coefficients)\n",
    "print (\"The Intercept of the model is : \", lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1747348707408,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "lLiqjQphVXQb"
   },
   "outputs": [],
   "source": [
    "# Se aplica el modelo al conjunto test\n",
    "Pred_lr = lr_model.evaluate(output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1729,
     "status": "ok",
     "timestamp": 1747348709258,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "WAP-f_vyVwNC",
    "outputId": "fcaa096f-917d-46e3-ed5a-a5921addb5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.786\n",
      "MSE: 22.906\n",
      "MAE: 3.614\n",
      "r2: 0.638\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Root Mean Square Error\n",
    "eval_lr = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_lr = eval_lr.evaluate(Pred_lr.predictions)\n",
    "print(\"RMSE: %.3f\" % rmse_lr)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval_lr.evaluate(Pred_lr.predictions, {eval_lr.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval_lr.evaluate(Pred_lr.predictions, {eval_lr.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = eval_lr.evaluate(Pred_lr.predictions, {eval_lr.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 2056,
     "status": "ok",
     "timestamp": 1747349688059,
     "user": {
      "displayName": "Ivan Olmos Pineda",
      "userId": "08486411851354884128"
     },
     "user_tz": 360
    },
    "id": "k3XQ2V2HHw8h"
   },
   "outputs": [],
   "source": [
    "# salvando el modelo lr_model y si existe sobreescribirlo\n",
    "lr_model.save(\"/content/drive/MyDrive/BigData_Maestria/Clase/lr_model\")\n",
    "# Leer el modelo del directorio\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "lr_model_loaded = LinearRegressionModel.load(\"/content/drive/MyDrive/BigData_Maestria/Clase/lr_model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhylKHFFBvJpjAbSc8Mxvo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

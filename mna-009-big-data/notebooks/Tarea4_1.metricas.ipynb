{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d562e69",
   "metadata": {},
   "source": [
    "# Actividad 4 | Métricas de calidad de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59655ca",
   "metadata": {},
   "source": [
    "Al finalizar esta actividad, habrás aprendido a aplicar diferentes estrategias para medir bajo diferentes métricas, la calidad de modelos de aprendizaje automático (supervisados o no supervisados) aplicados al procesamiento de grandes volúmenes de datos (Big Data), usando la biblioteca PySpark. Para esta actividad, se estará trabajando con la muestra representativa M de la población P del problema de investigación que decidiste seleccionar desde el inicio del curso, además de retomar los criterios de particionamiento definidos en la actividad 3 del Módulo 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DateType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    DoubleType,\n",
    "    BooleanType,\n",
    ")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import (\n",
    "    LinearRegression,\n",
    "    GBTRegressor,\n",
    ")\n",
    "from pyspark.ml.feature import (\n",
    "    StandardScaler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler,\n",
    "    QuantileDiscretizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9a3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much memory from the available in the machine I'm able to use\n",
    "EXECUTOR_MEMORY = \"100G\"\n",
    "DRIVER_MEMORY = \"20G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6d5e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/07 14:40:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"flights\")\n",
    "    .config(\"spark.executor.memory\", EXECUTOR_MEMORY)\n",
    "    .config(\"spark.driver.memory\", DRIVER_MEMORY)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.sparkContext.setCheckpointDir(\"./data/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e115b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be changed according to the environment\n",
    "filepath = \"./data/flights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf8ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f\"Combined_Flights_{y}.csv\" for y in range(2018, 2019)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2763d5b",
   "metadata": {},
   "source": [
    "### Carga de Archivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324e32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"FlightDate\", DateType(), True),\n",
    "        StructField(\"Airline\", StringType(), True),\n",
    "        StructField(\"Origin\", StringType(), True),\n",
    "        StructField(\"Dest\", StringType(), True),\n",
    "        StructField(\"Cancelled\", BooleanType(), True),\n",
    "        StructField(\"Diverted\", StringType(), True),\n",
    "        StructField(\"CRSDepTime\", IntegerType(), True),\n",
    "        StructField(\"DepTime\", DoubleType(), True),\n",
    "        StructField(\"DepDelayMinutes\", DoubleType(), True),\n",
    "        StructField(\"DepDelay\", DoubleType(), True),\n",
    "        StructField(\"ArrTime\", DoubleType(), True),\n",
    "        StructField(\"ArrDelayMinutes\", DoubleType(), True),\n",
    "        StructField(\"AirTime\", DoubleType(), True),\n",
    "        StructField(\"CRSElapsedTime\", DoubleType(), True),\n",
    "        StructField(\"ActualElapsedTime\", DoubleType(), True),\n",
    "        StructField(\"Distance\", DoubleType(), True),\n",
    "        StructField(\"Year\", IntegerType(), True),\n",
    "        StructField(\"Quarter\", IntegerType(), True),\n",
    "        StructField(\"Month\", IntegerType(), True),\n",
    "        StructField(\"DayofMonth\", IntegerType(), True),\n",
    "        StructField(\"DayOfWeek\", IntegerType(), True),\n",
    "        StructField(\"Marketing_Airline_Network\", StringType(), True),\n",
    "        StructField(\"Operated_or_Branded_Code_Share_Partners\", StringType(), True),\n",
    "        StructField(\"DOT_ID_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"IATA_Code_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"Flight_Number_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"Operating_Airline\", StringType(), True),\n",
    "        StructField(\"DOT_ID_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"IATA_Code_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"Tail_Number\", StringType(), True),\n",
    "        StructField(\"Flight_Number_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"OriginAirportID\", StringType(), True),\n",
    "        StructField(\"OriginAirportSeqID\", StringType(), True),\n",
    "        StructField(\"OriginCityMarketID\", StringType(), True),\n",
    "        StructField(\"OriginCityName\", StringType(), True),\n",
    "        StructField(\"OriginState\", StringType(), True),\n",
    "        StructField(\"OriginStateFips\", StringType(), True),\n",
    "        StructField(\"OriginStateName\", StringType(), True),\n",
    "        StructField(\"OriginWac\", StringType(), True),\n",
    "        StructField(\"DestAirportID\", StringType(), True),\n",
    "        StructField(\"DestAirportSeqID\", StringType(), True),\n",
    "        StructField(\"DestCityMarketID\", StringType(), True),\n",
    "        StructField(\"DestCityName\", StringType(), True),\n",
    "        StructField(\"DestState\", StringType(), True),\n",
    "        StructField(\"DestStateFips\", StringType(), True),\n",
    "        StructField(\"DestStateName\", StringType(), True),\n",
    "        StructField(\"DestWac\", StringType(), True),\n",
    "        StructField(\"DepDel15\", StringType(), True),\n",
    "        StructField(\"DepartureDelayGroups\", StringType(), True),\n",
    "        StructField(\"DepTimeBlk\", StringType(), True),\n",
    "        StructField(\"TaxiOut\", DoubleType(), True),\n",
    "        StructField(\"WheelsOff\", DoubleType(), True),\n",
    "        StructField(\"WheelsOn\", DoubleType(), True),\n",
    "        StructField(\"TaxiIn\", DoubleType(), True),\n",
    "        StructField(\"CRSArrTime\", IntegerType(), True),\n",
    "        StructField(\"ArrDelay\", DoubleType(), True),\n",
    "        StructField(\"ArrDel15\", StringType(), True),\n",
    "        StructField(\"ArrivalDelayGroups\", StringType(), True),\n",
    "        StructField(\"ArrTimeBlk\", StringType(), True),\n",
    "        StructField(\"DistanceGroup\", StringType(), True),\n",
    "        StructField(\"DivAirportLandings\", StringType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105fc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_from(path: str, files: list[str], schema) -> DataFrame:\n",
    "    df = spark.createDataFrame([], schema=schema)\n",
    "    dataframes = [\n",
    "        spark.read.csv(f\"{filepath}/{filename}\", header=True, schema=schema)\n",
    "        for filename in files\n",
    "    ]\n",
    "    return functools.reduce(DataFrame.unionAll, dataframes, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612dead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_files_from(filepath, filenames, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8abf20",
   "metadata": {},
   "source": [
    "### Limpieza de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bca521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5689512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of original rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6e00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5578618"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with null values\n",
    "clean_df = df.dropna()\n",
    "\n",
    "# drop columns with null values\n",
    "clean_df = clean_df.na.drop()\n",
    "\n",
    "# drop duplicated rows\n",
    "clean_df = clean_df.dropDuplicates().coalesce(numPartitions=multiprocessing.cpu_count()).checkpoint()\n",
    "\n",
    "# number of rows after cleaning\n",
    "clean_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22dcf3",
   "metadata": {},
   "source": [
    "Definition of categorical columns, continuous columns and label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3ea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"ArrDelay\"\n",
    "\n",
    "\n",
    "continuous_cols = [\n",
    "    el.name\n",
    "    for el in df.schema\n",
    "    if isinstance(el.dataType, (DoubleType, IntegerType))\n",
    "    and el.name not in [\"Year\", \"Quarter\", \"Month\", \"DayofMonth\", \"DayOfWeek\"]\n",
    "]\n",
    "\n",
    "categorica_cols = [\n",
    "    \"Marketing_Airline_Network\",\n",
    "    \"Operating_Airline\",\n",
    "    \"OriginAirportID\",\n",
    "    \"DestAirportID\",\n",
    "    \"OriginCityName\",\n",
    "    \"DestCityName\",\n",
    "    \"DayOfWeek\",\n",
    "    \"Month\",\n",
    "    \"DistanceGroup\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d26a25",
   "metadata": {},
   "source": [
    "## Construcción de la muestra M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ce9ee",
   "metadata": {},
   "source": [
    "1. Construir una muestra M que sea representativa de la población P (a partir del dataset que recolectaste desde el inicio del curso). Tomando como base el conocimiento adquirido en la Actividad 3 del Módulo 4, generarás particiones Mi de M, donde cada Mi cumple con los criterios definidos por las variables de caracterización que identificaste previamente (M será igual a la unión de todos los Mi). Para esta actividad, y a diferencia del paso previo, se deberá de tener especial cuidado para determinar el número de instancias que deberá contender cada partición Mi a generar, de tal forma que no se inyecte ningún tipo de sesgo que pueda alterar la calidad de los resultados. Como resultado, crearás una sección en el archivo Jupyter Notebook a entregar llamada “1 Construcción de la muestra M”, donde en código Python y haciendo uso de PySpark, generarás las particiones derivadas del análisis hecho. Cada paso deberá ser documentado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365198ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|kurtosis(ArrDelay)|skewness(ArrDelay)|\n",
      "+------------------+------------------+\n",
      "|143.93258992452914| 8.468000271818116|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the kurtosis and skewness\n",
    "clean_df.select(F.kurtosis(label), F.skewness(label)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1644ae8",
   "metadata": {},
   "source": [
    "La variable presenta una asimetria positiva significativa lo que indica que la distribucion de los restrasos en la llegada esta sesgada a la derecha, es decir, que hay una concentracion de vuelos con pocos o ningun retraso, pero existen algunos vuelos con retrasos extremadamente altos.\n",
    "\n",
    "El valor de kustosis extremadamente alto sugiere que la distribucion tiene colar pesadas y picos pronunciados lo que indica un presencia muy fuerte de valores atipicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965dc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 13\n",
    "\n",
    "# Create a Discrete output over a continuous column\n",
    "quantile_discretizer = QuantileDiscretizer(\n",
    "    numBuckets=num_bins, inputCol=label, outputCol=f\"{label}_discrete\"\n",
    ")\n",
    "\n",
    "clean_bin_df = quantile_discretizer.fit(clean_df).transform(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb722dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get distinct categories in a list\n",
    "categories = (\n",
    "    clean_bin_df.select(f\"{label}_discrete\")\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf01d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = []\n",
    "\n",
    "# Iterate the categories and create a sample\n",
    "for cat in categories:\n",
    "    df_cat = clean_bin_df.filter(F.col(f\"{label}_discrete\") == cat)\n",
    "    fraction = 0.1\n",
    "    sample = (\n",
    "        df_cat.drop(f\"{label}_discrete\")\n",
    "        .sample(withReplacement=False, fraction=fraction, seed=42)\n",
    "    )\n",
    "    partitions.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ab560ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Union all samples again\n",
    "__df = spark.createDataFrame([], schema=schema)\n",
    "sample_df = functools.reduce(DataFrame.unionAll, partitions, __df).coalesce(numPartitions=multiprocessing.cpu_count()).checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf04ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in the sample\n",
    "sample_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed3dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|kurtosis(ArrDelay)|skewness(ArrDelay)|\n",
      "+------------------+------------------+\n",
      "|142.47484681309507| 8.550897072406542|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the kurtosis and skewness\n",
    "sample_df.select(F.kurtosis(label), F.skewness(label)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8496f8",
   "metadata": {},
   "source": [
    "## Construcción Train – Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57320464",
   "metadata": {},
   "source": [
    "2. Construcción del conjunto de entrenamiento y prueba. Para este paso se asume que M = {Mi: Mi es una partición derivada de las variables de caracterización de la población} generada en el paso anterior. Para construir el conjunto de entrenamiento y prueba, se debe de calcular el porcentaje de división a usar, de tal forma que al dividir cada Mi en un conjunto de entrenamiento (Tri) y prueba (Tsi), no se inyecten sesgos que desvíen la probabilidad de ocurrencia de los patrones en cada nueva partición. Para ello, deberás de retomar la estrategia de muestreo propuesta en el paso 4 de la Actividad 3 del módulo 4. Se debe de cuidar que Tri Ç Tsi = Æ, además de que la unión de todas las particiones es igual a M. Como evidencia, se generará una nueva sección en el archivo Jupyter Notebook que construyes, llamada “2 Construcción Train – Test”, en dónde generes el código correspondiente en Python que implemente lo antes solicitado. Todo deberá de estar debidamente documentado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6e09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bin_df = quantile_discretizer.fit(sample_df).transform(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ac33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = (\n",
    "    sample_bin_df.select(f\"{label}_discrete\")\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e5572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partitions = []\n",
    "test_partitions = []\n",
    "\n",
    "# Iterate the categories and create a sample\n",
    "for cat in categories:\n",
    "    # Create stratum\n",
    "    stratum_df = sample_bin_df.filter(F.col(f\"{label}_discrete\") == cat)\n",
    "\n",
    "    # Separate in train and test\n",
    "    train_stratum_df, test_stratum_df = stratum_df.limit(10000).drop(\n",
    "        f\"{label}_discrete\"\n",
    "    ).randomSplit([0.7, 0.3])\n",
    "\n",
    "    train_partitions.append(train_stratum_df.cache())\n",
    "    test_partitions.append(test_stratum_df.cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc3f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "__df = spark.createDataFrame([], schema=schema)\n",
    "\n",
    "train_df = functools.reduce(DataFrame.unionAll, train_partitions, __df).coalesce(numPartitions=multiprocessing.cpu_count()).checkpoint()\n",
    "\n",
    "test_df = functools.reduce(DataFrame.unionAll, test_partitions, __df).coalesce(numPartitions=multiprocessing.cpu_count()).checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa9b8d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|kurtosis(ArrDelay)|skewness(ArrDelay)|\n",
      "+------------------+------------------+\n",
      "| 142.2852689839089| 8.677594843565547|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(F.kurtosis(label), F.skewness(label)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb591cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|kurtosis(ArrDelay)|skewness(ArrDelay)|\n",
      "+------------------+------------------+\n",
      "|130.94558909645903| 8.301698308041166|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.select(F.kurtosis(label), F.skewness(label)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c5c43",
   "metadata": {},
   "source": [
    "## Selección de métricas para medir calidad de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9a259",
   "metadata": {},
   "source": [
    "3. Con la finalidad de medir la calidad de resultados que se obtienen, se debe de seleccionar previamente métricas para su medición. Se recomienda que se analice a profundidad que métricas se pueden aplicar, considerando que se trabaja con grandes volúmenes de datos. Para evidenciar el análisis hecho, crearás una sección llamada “3 Selección de métricas para medir calidad de resultados”, dónde argumentarás que métricas serán usadas para medir la calidad de los modelos derivados de la etapa de entrenamiento. Dichas métricas se deberán de implementar en tu etapa de experimentación del paso 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e6a69",
   "metadata": {},
   "source": [
    "**Mean Square Error**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Penaliza fuertemente los errores grandes, lo que lo hace útil cuando estos son especialmente indeseables.\n",
    "- Es diferenciable, lo cual lo convierte en una función de pérdida adecuada para algoritmos de optimización basados en gradiente.\n",
    "\n",
    "Desventajas\n",
    "\n",
    "- Es sensible a los valores atípicos (outliers), ya que los errores se elevan al cuadrado.\n",
    "- La métrica no conserva las unidades originales de la variable objetivo, lo que puede dificultar la interpretación directa de los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34398fb4",
   "metadata": {},
   "source": [
    "**Root Mean Square Error**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Está en las mismas unidades que la variable objetivo, lo que facilita la interpretación de los resultados.\n",
    "- Penaliza más los errores grandes, al igual que el MSE, lo cual es útil cuando los errores grandes son más perjudiciales.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Sigue siendo sensible a los valores atípicos (outliers), ya que también se basa en el cuadrado de los errores antes de tomar la raíz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34525061",
   "metadata": {},
   "source": [
    "**Mean Absolute Error**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Robusto frente a valores atípicos, ya que no eleva los errores al cuadrado.\n",
    "- Fácil de interpretar, ya que representa el error promedio en las mismas unidades que la variable objetivo.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- No penaliza los errores grandes tan fuertemente como el MSE o RMSE, lo que puede ser una desventaja cuando los errores grandes son especialmente críticos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3842a97",
   "metadata": {},
   "source": [
    "**Coeficiente de Determinacion (R^2)**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Interpretación intuitiva, ya que indica la proporción de la varianza explicada por el modelo.\n",
    "- Ampliamente utilizado en regresión lineal, lo que lo hace familiar y fácil de comunicar.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- No penaliza la inclusión de variables irrelevantes, lo que puede llevar a sobreajuste si se agregan demasiadas características.\n",
    "- No es adecuado para modelos no lineales, ya que puede dar valores engañosos fuera del contexto de regresión lineal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2899f5",
   "metadata": {},
   "source": [
    "**Coeficiente de Determinacion (R^2) Ajustado**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Se ajusta según el número de predictores, lo que lo hace más adecuado que el R² tradicional para modelos de regresión múltiple.\n",
    "- Útil para comparar modelos con diferente cantidad de variables, ya que penaliza la inclusión de predictores irrelevantes.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Más complejo de calcular que el R² estándar, especialmente al explicar su fórmula o interpretación.\n",
    "- Menos informativo en modelos con un solo predictor, donde su valor suele ser muy similar al de R².\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c1df2",
   "metadata": {},
   "source": [
    "**Mean Absolute Percentage Error**\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Interpretabilidad: Al expresarse en porcentaje, el MAPE es intuitivo y facilita la comparación del rendimiento del modelo entre diferentes conjuntos de datos.\n",
    "- Medida relativa del error: Es útil cuando se trabaja con datos de distintas escalas, ya que proporciona una visión proporcional del error respecto a los valores reales.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Sensibilidad a valores reales pequeños: Si los valores reales son muy cercanos a cero, el error porcentual se amplifica de forma desproporcionada, distorsionando la evaluación.\n",
    "- Indefinido para valores reales iguales a cero: Cuando el valor real es cero, el MAPE no puede calcularse, lo que limita su aplicabilidad en ciertos conjuntos de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e102bb",
   "metadata": {},
   "source": [
    "### Metricas Seleccionadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a884d",
   "metadata": {},
   "source": [
    "1. Root Mean Square Error\n",
    "\n",
    "- Preserva las unidades originales (minutos de retraso), lo que facilita su interpretación por parte de los stakeholders.\n",
    "- Penaliza fuertemente los errores grandes, lo cual es adecuado para este caso, ya que los retrasos extremos (por ejemplo, superiores a 180 minutos) tienen un impacto desproporcionado en los pasajeros, las aerolíneas y las operaciones aeroportuarias.\n",
    "- Amplia aceptación en la industria del transporte y la aviación para tareas de predicción de retrasos.\n",
    "\n",
    "2. Mean Absolute Error\n",
    "\n",
    "- Más robusta ante valores atípicos que el RMSE, lo cual es relevante dada la distribución sesgada y con colas pesadas del conjunto de datos.\n",
    "- Interpretación directa y clara: indica el promedio absoluto de error en minutos, lo que permite comunicar fácilmente la precisión del modelo (por ejemplo, “en promedio, el modelo se equivoca por X minutos”).\n",
    "\n",
    "3. Coefiente de Determinacion (R^2)\n",
    "\n",
    "- Interpretación útil: El R² indica la proporción de la varianza en los retrasos que puede ser explicada por el modelo. Un valor cercano a 1 sugiere que el modelo captura bien la dinámica subyacente del problema; un valor cercano a 0 indica que apenas mejora respecto a una predicción basada en la media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1a679",
   "metadata": {},
   "source": [
    "## Entrenamiento de Modelos de Aprendizaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6261b6",
   "metadata": {},
   "source": [
    "4. Construcción de modelos de aprendizaje. Para esta etapa y partiendo de la elección de algoritmos de aprendizaje (supervisado, no supervisado), aplicarás un proceso de entrenamiento que te permita construir modelos de aprendizaje que ayude a identificar los patrones de interés existentes en los datos. Se deberá de tener en claro la estrategia de entrenamiento a implementar, desde la forma en la cual se procesarán los datos hasta el ajuste de hiper – parámetros a emplear, además de los ajustes y técnicas adicionales que impidan que los modelos generados estén sobre- ajustados. Lo anterior lo deberás de aterrizar en una sección del Jupyter Notebook que se construye llamada “4 Entrenamiento de Modelos de Aprendizaje”. Se deberá documentar dicho proceso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30706834",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumnRenamed(label, \"label\")\n",
    "test_df = test_df.withColumnRenamed(label, \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "467e22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_pipeline(input_col: str):\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=input_col, outputCol=f\"{input_col}_indexed\", handleInvalid=\"keep\"\n",
    "    )\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCol=f\"{input_col}_indexed\", outputCol=f\"{input_col}_vec\"\n",
    "    )\n",
    "    return Pipeline(stages=[indexer, encoder]), f\"{input_col}_vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5200bb9",
   "metadata": {},
   "source": [
    "### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c535cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_regresion_pipeline(\n",
    "    continuous: list[str], categorical: list[str], label: str\n",
    ") -> TrainValidationSplit:\n",
    "    one_hot_pipelines = []\n",
    "    for categorical_column in categorical:\n",
    "        pipe, col = one_hot_pipeline(categorical_column)\n",
    "        one_hot_pipelines.append((pipe, col))\n",
    "\n",
    "    assembled_columns = [col for col in continuous if col != label] + [\n",
    "        col[1] for col in one_hot_pipelines\n",
    "    ]\n",
    "    assembler = VectorAssembler(inputCols=assembled_columns, outputCol=\"features\")\n",
    "\n",
    "    scaler = StandardScaler(\n",
    "        withMean=False, withStd=True, inputCol=\"features\", outputCol=\"scaled_features\"\n",
    "    )\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=[col[0] for col in one_hot_pipelines] + [assembler, scaler, model]\n",
    "    )\n",
    "\n",
    "    paramGrid = (\n",
    "        ParamGridBuilder()\n",
    "        .addGrid(model.regParam, [0.0, 0.01, 0.1, 1.0])\n",
    "        .addGrid(model.fitIntercept, [False, True])\n",
    "        .addGrid(model.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "        .addGrid(model.tol, [1e-4, 1e-6])\n",
    "        .addGrid(model.maxIter, [10, 50])\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    return TrainValidationSplit(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=RegressionEvaluator(),\n",
    "        trainRatio=0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68d61e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_linear_regresion_pipeline(continuous_cols, categorica_cols, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7adfa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb78f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('./models/lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bff195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = model.transform(test_df).select(\"features\", \"label\", \"prediction\").checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "157702ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58f7b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator_rmse.evaluate(prediction_df)\n",
    "mae = evaluator_mae.evaluate(prediction_df)\n",
    "r2 = evaluator_r2.evaluate(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d5ca2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.31309453379273, MAE: 1.7675790522963606, R^2: 0.997675624163221\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {rmse}, MAE: {mae}, R^2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb7dc5",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gbt_regresion_pipeline(\n",
    "    continuous: list[str], categorical: list[str], label: str\n",
    ") -> TrainValidationSplit:\n",
    "    one_hot_pipelines = []\n",
    "    for categorical_column in categorical:\n",
    "        pipe, col = one_hot_pipeline(categorical_column)\n",
    "        one_hot_pipelines.append((pipe, col))\n",
    "\n",
    "    assembled_columns = [col for col in continuous if col != label] + [\n",
    "        col[1] for col in one_hot_pipelines\n",
    "    ]\n",
    "    assembler = VectorAssembler(inputCols=assembled_columns, outputCol=\"features\")\n",
    "\n",
    "    scaler = StandardScaler(\n",
    "        withMean=False, withStd=True, inputCol=\"features\", outputCol=\"scaled_features\"\n",
    "    )\n",
    "\n",
    "    model = GBTRegressor()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=[col[0] for col in one_hot_pipelines] + [assembler, scaler, model]\n",
    "    )\n",
    "\n",
    "    paramGrid = (\n",
    "        ParamGridBuilder()\n",
    "        .addGrid(model.maxDepth, [5, 10, 15])\n",
    "        .addGrid(model.maxBins, [16, 64])\n",
    "        .addGrid(model.stepSize, [0.05, 0.1])\n",
    "        .addGrid(model.maxIter, [10, 50])\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    return TrainValidationSplit(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=RegressionEvaluator(),\n",
    "        trainRatio=0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e194980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_gbt_regresion_pipeline(continuous_cols, categorica_cols, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05af03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1cb42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('./models/gbt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c57fecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = model.transform(test_df).select(\"features\", \"label\", \"prediction\").checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91d7becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11478a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator_rmse.evaluate(prediction_df)\n",
    "mae = evaluator_mae.evaluate(prediction_df)\n",
    "r2 = evaluator_r2.evaluate(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1f5d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 14.189673242940854, MAE: 2.6733151733503244, R^2: 0.9125289425323351\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {rmse}, MAE: {mae}, R^2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c24c9",
   "metadata": {},
   "source": [
    "## Análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5008fc",
   "metadata": {},
   "source": [
    "5. Análisis de resultados. Para esta última etapa del proceso, analizarás en profundidad los resultados obtenidos a partir del proceso de entrenamiento implementado. Se deberá de crear una sección titulada “5 Análisis de resultados”, en la cual incluya una profunda reflexión de los resultados alcanzados, identificando sus fortalezas y áreas de oportunidad de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee3f94",
   "metadata": {},
   "source": [
    "En este análisis se ha evaluado el rendimiento de diferentes modelos de regresión aplicados para predecir los retrasos en la llegada de vuelos, utilizando métricas como RMSE, MAE y R².\n",
    "\n",
    "**Fortalezas:**\n",
    "- **Interpretabilidad de las métricas:** Las medidas de error (RMSE y MAE) proporcionan una comprensión clara de la magnitud de los errores en minutos, lo que es crucial para un análisis aplicado en el ámbito aeroportuario.\n",
    "- **Captura de relaciones complejas:** La implementación de modelos tanto lineales como de Gradient-Boosted Trees ha permitido capturar tanto relaciones lineales como no lineales en los datos, adaptándose a la distribución sesgada y a la presencia de valores atípicos.\n",
    "- **Representatividad de los datos:** La cuidadosa construcción de la muestra M y la subsiguiente partición estratificada para entrenamiento y prueba han contribuido a minimizar sesgos en la estimación del rendimiento de los modelos.\n",
    "- **Utilización de técnicas de escalado y codificación:** El uso de pipelines para One-Hot Encoding y escalado de características ha facilitado el procesamiento consistente y reproducible de las variables, lo que ayuda a estabilizar el comportamiento de los modelos.\n",
    "\n",
    "**Áreas de oportunidad:**\n",
    "- **Manejo de valores atípicos:** Dada la fuerte asimetría y la presencia de colas pesadas en la variable objetivo, existe la posibilidad de explorar técnicas de transformación (como logaritmos) o modelos robustos que mitiguen el efecto de los valores extremos.\n",
    "- **Optimización de hiperparámetros:** Si bien se ha realizado una búsqueda de hiperparámetros, la implementación de estrategias más exhaustivas o el uso de validación cruzada más profunda podría mejorar aún más el desempeño de los modelos.\n",
    "- **Ampliación del conjunto de modelos:** La exploración de otros algoritmos, incluyendo enfoques de aprendizaje profundo, podría ofrecer mejoras adicionales y capturar de forma más precisa patrones complejos presentes en los datos.\n",
    "- **Análisis de errores y visualización:** Un análisis más detallado de los errores de predicción y la incorporación de técnicas de visualización adicionales permitirían una interpretación más rica de los resultados, facilitando la comunicación a stakeholders no técnicos.\n",
    "\n",
    "En conclusión, los modelos desarrollados muestran un desempeño prometedor en la predicción de retrasos, sustentado por un conjunto significativo de métricas. Sin embargo, los retos derivados de la distribución de la variable actividad sugieren que explorar estrategias adicionales de preprocesamiento, validación y selección de modelos podría conducir a soluciones aún más robustas y precisas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-analytics-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c468023",
   "metadata": {},
   "source": [
    "# Reglas de Particionamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bae914",
   "metadata": {},
   "source": [
    "## Descripcion de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fdd2b9",
   "metadata": {},
   "source": [
    "Dentro del campo de la ciencia de datos, nos interesa especialmente realizar análisis exploratorios sobre diversos tipos de datos. El objetivo es generar predicciones fundamentadas en el comportamiento pasado, lo que permite comprender mejor el comportamiento futuro.\n",
    "\n",
    "Por esta razón, busqué una base de datos con información histórica y diversas categorías, que fuera ideal para realizar análisis exploratorios por categoría, comparaciones entre ellas y que contuviera el material necesario para generar predicciones futuras.\n",
    "\n",
    "La base de datos Flight Status Predict cumplió con estas características. Además, aborda un tema que me resulta interesante: determinar qué factores podrían afectar las cancelaciones, retrasos, y las mejores aerolíneas para viajar en mis próximas vacaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e34f20",
   "metadata": {},
   "source": [
    "## Reglas de particionamiento Seleccionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2fd80",
   "metadata": {},
   "source": [
    "- Ocurrencia entre nombre comercial y nombre operativo de aerolineas\n",
    "- Ocurrencia entre Dia de la Semana y Mes\n",
    "- Ocurrencia entre Nombre Comercial de la Aerolinea y `DistanceGroup`\n",
    "- Ocurrencia vuelos entre la Aerolinea y el mes\n",
    "- Ocurrencia de vuelos entre la Aerolinea y el dia de la semana\n",
    "- Ocurrencia entre Aerolinea y la ciudad origen del vuelo\n",
    "- Ocurrencia entre la Aerolinea y la ciudad destino en el vuelo\n",
    "- Ocurrencia entre ciudad origen y destino\n",
    "\n",
    "Nota: La variable `DistanceGroup` es un numero entero que representa una agrupacion de cada 500 millas recorridas por el vuelo del avion, es decir si `DistanceGroup = 2` el recorrido seria no mas de 1000 millas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbeac6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import operator\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, DateType, IntegerType, StringType, DoubleType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b149259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 21:24:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                .appName(\"flights\") \\\n",
    "                .config(\"spark.executor.memory\", \"10G\") \\\n",
    "                .config(\"spark.driver.memory\", \"2G\") \\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25972b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"FlightDate\", DateType(), True),\n",
    "        StructField(\"Airline\", StringType(), True),\n",
    "        StructField(\"Origin\", StringType(), True),\n",
    "        StructField(\"Dest\", StringType(), True),\n",
    "        StructField(\"Cancelled\", BooleanType(), True),\n",
    "        StructField(\"Diverted\", BooleanType(), True),\n",
    "        StructField(\"CRSDepTime\", IntegerType(), True),\n",
    "        StructField(\"DepTime\", DoubleType(), True),\n",
    "        StructField(\"DepDelayMinutes\", DoubleType(), True),\n",
    "        StructField(\"DepDelay\", DoubleType(), True),\n",
    "        StructField(\"ArrTime\", DoubleType(), True),\n",
    "        StructField(\"ArrDelayMinutes\", DoubleType(), True),\n",
    "        StructField(\"AirTime\", DoubleType(), True),\n",
    "        StructField(\"CRSElapsedTime\", DoubleType(), True),\n",
    "        StructField(\"ActualElapsedTime\", DoubleType(), True),\n",
    "        StructField(\"Distance\", DoubleType(), True),\n",
    "        StructField(\"Year\", IntegerType(), True),\n",
    "        StructField(\"Quarter\", IntegerType(), True),\n",
    "        StructField(\"Month\", IntegerType(), True),\n",
    "        StructField(\"DayofMonth\", IntegerType(), True),\n",
    "        StructField(\"DayOfWeek\", IntegerType(), True),\n",
    "        StructField(\"Marketing_Airline_Network\", StringType(), True),\n",
    "        StructField(\"Operated_or_Branded_Code_Share_Partners\", StringType(), True),\n",
    "        StructField(\"DOT_ID_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"IATA_Code_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"Flight_Number_Marketing_Airline\", StringType(), True),\n",
    "        StructField(\"Operating_Airline\", StringType(), True),\n",
    "        StructField(\"DOT_ID_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"IATA_Code_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"Tail_Number\", StringType(), True),\n",
    "        StructField(\"Flight_Number_Operating_Airline\", StringType(), True),\n",
    "        StructField(\"OriginAirportID\", StringType(), True),\n",
    "        StructField(\"OriginAirportSeqID\", StringType(), True),\n",
    "        StructField(\"OriginCityMarketID\", StringType(), True),\n",
    "        StructField(\"OriginCityName\", StringType(), True),\n",
    "        StructField(\"OriginState\", StringType(), True),\n",
    "        StructField(\"OriginStateFips\", StringType(), True),\n",
    "        StructField(\"OriginStateName\", StringType(), True),\n",
    "        StructField(\"OriginWac\", StringType(), True),\n",
    "        StructField(\"DestAirportID\", StringType(), True),\n",
    "        StructField(\"DestAirportSeqID\", StringType(), True),\n",
    "        StructField(\"DestCityMarketID\", StringType(), True),\n",
    "        StructField(\"DestCityName\", StringType(), True),\n",
    "        StructField(\"DestState\", StringType(), True),\n",
    "        StructField(\"DestStateFips\", StringType(), True),\n",
    "        StructField(\"DestStateName\", StringType(), True),\n",
    "        StructField(\"DestWac\", StringType(), True),\n",
    "        StructField(\"DepDel15\", StringType(), True),\n",
    "        StructField(\"DepartureDelayGroups\", StringType(), True),\n",
    "        StructField(\"DepTimeBlk\", StringType(), True),\n",
    "        StructField(\"TaxiOut\", DoubleType(), True),\n",
    "        StructField(\"WheelsOff\", DoubleType(), True),\n",
    "        StructField(\"WheelsOn\", DoubleType(), True),\n",
    "        StructField(\"TaxiIn\", DoubleType(), True),\n",
    "        StructField(\"CRSArrTime\", IntegerType(), True),\n",
    "        StructField(\"ArrDelay\", DoubleType(), True),\n",
    "        StructField(\"ArrDel15\", StringType(), True),\n",
    "        StructField(\"ArrivalDelayGroups\", StringType(), True),\n",
    "        StructField(\"ArrTimeBlk\", StringType(), True),\n",
    "        StructField(\"DistanceGroup\", StringType(), True),\n",
    "        StructField(\"DivAirportLandings\", StringType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6284de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./data/flights\"\n",
    "filenames = [ f\"Combined_Flights_{y}.csv\" for y in range(2018, 2023) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45c672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_rules = [('Marketing_Airline_Network', 'Operating_Airline'), ('DayOfWeek', 'Month'), ('Marketing_Airline_Network', 'DistanceGroup'), ('Marketing_Airline_Network', 'Month'),('Marketing_Airline_Network', 'DayOfWeek'), ('Marketing_Airline_Network', 'OriginCityName'), ('Marketing_Airline_Network', 'DestCityName'), ('OriginCityName', 'DestCityName')]\n",
    "partition_rules_filenames = [ f\"Combined_Flights_2018_Rule_{rule[0]}_{rule[1]}\" for rule in partition_rules ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d2826",
   "metadata": {},
   "source": [
    "# Muestreo basado en Reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff99de",
   "metadata": {},
   "source": [
    "El siguiente codigo filtra la base de datos de vuelos para obtener una muestra de acuerdo a las 3 reglas de mayor ocurrencia segun el paso anterior.\n",
    "\n",
    " - Se imprime la cantidad de filas resultantes para cada base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c13e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 21:24:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25741\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.schema(schema).csv(f\"{filepath}/{filenames[0]}\", header=True)\n",
    "\n",
    "for filename, names in zip(partition_rules_filenames, partition_rules):\n",
    "    rule = spark.read.parquet(f\"{filepath}/{filename}\")\n",
    "    l = 3\n",
    "    \n",
    "    # rule.columns[:-1] son las dos columnas (p. ej. ['Marketing_Airline_Network','Operating_Airline']) usadas para la unión.\n",
    "    # El inner join devuelve solo las filas de df cuyas tuplas en esas dos columnas coinciden con alguna de las 2 seleccionadas.\n",
    "    # Luego recuperamos todas las columnas originales con .select(*df.columns)\n",
    "    # Asumimos que el parquet de cada regla está ordenado por frecuencia descendente, de modo que limit(3) recoge las 3 combinaciones (tuplas de valores) que más se repiten según esa regla.\n",
    "    database = df.join(rule.limit(l), rule.columns[:-1], 'inner').select(*df.columns)\n",
    "\n",
    "    database.repartition(1).write.mode('overwrite').format('parquet').save(f\"./data/flights/{filenames[0][:-4]}_Final_DB_{names[0]}-{names[1]}\")\n",
    "    \n",
    "    # Impresion de la cantidad de filas resultantes en cada particion\n",
    "    print(database.count())\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98452fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-analytics-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

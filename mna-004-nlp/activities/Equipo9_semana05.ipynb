{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9db2e4mzvP1"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Adtividad Semana 5\n",
        "\n",
        "### **Vectores Embebidos Pre-entrenados: Fasttext**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwT6mxQvz294"
      },
      "source": [
        "#### **Nombres y matrículas de los integrantes del equipo:**\n",
        "Equipo 9:\n",
        "\n",
        "Yohanna Ceballos Salomón | A01795115\n",
        "\n",
        "Mauricio Castilo Galindo | A01795453\n",
        "\n",
        "Juan Manuel Carballo M. | A01166758\n",
        "\n",
        "Andrea Cantú Martínez | A01235000\n",
        "\n",
        "Armando Cerda De La Rosa | A01570376\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbu45RaP3wUj",
        "outputId": "2c80e23b-d949-4827-b4d5-b0877f09e18c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "import os\n",
        "\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRQbytuA5rm9",
        "outputId": "eff5b8f7-63ea-47bb-df32-2466bdda4593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpWEOemp31yI"
      },
      "source": [
        "Descarga los 3 archivos de Canvas y genera un nuevo DataFrame de Pandas con ellos.\n",
        "\n",
        "**Llama simplemente \"df\" a dicho DataFrame.**\n",
        "\n",
        "Los archivos los encuentras en Canvas: amazon5.txt, imdb5.txt, yelp5.txt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxUDAXRo2BOQ"
      },
      "source": [
        "\n",
        "Descarga los 3 archivos de Canvas y genera un solo DataFrame de Pandas con ellos. En particular, el\n",
        "archivo de datos de IMDb ya no requiere transformarse para obtener sus 1000 registros. Verifica\n",
        "que tienes los 3000 registros con sus respectivas etiquetas en dicho DataFrame. Los archivos los\n",
        "encuentras en Canvas y se llaman: amazon5.txt, imdb5.txt, yelp5.txt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hhAFpndznJ5",
        "outputId": "90408bd2-70f0-4ed1-808f-dddde62a4a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros de Amazon: (1000, 2)\n",
            "Total de registros de IMBD: (1000, 2)\n",
            "Total de registros de Yelp: (1000, 2)\n",
            "\n",
            "\n",
            "label\n",
            "0    1500\n",
            "1    1500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Drive\n",
        "DIR = \"/content/drive/MyDrive/Colab Notebooks/MNA/Procesamiento de Lenguaje Natural\"\n",
        "os.chdir(DIR)\n",
        "\n",
        "dfa = pd.read_csv('amazon5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfi = pd.read_csv('imdb5.txt', sep='\\s{3,}', names=['review','label'], header=None, encoding='utf-8', engine='python')\n",
        "dfy = pd.read_csv('yelp5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "\n",
        "print('Total de registros de Amazon:',dfa.shape)\n",
        "print('Total de registros de IMBD:',dfi.shape)\n",
        "print('Total de registros de Yelp:',dfy.shape)\n",
        "\n",
        "df = pd.concat([dfa, dfi, dfy], ignore_index=True)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwPhJHMJGQTf",
        "outputId": "8860d501-2030-4a64-f789-e9cef0f6ea35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  3000 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Verifiquemos la información del DataFrame:\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GDxcTcFj4NN3",
        "outputId": "303142ec-46bf-4983-e398-390fccc0d6e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e2d2196-484c-4eca-b102-45a7e751e41b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e2d2196-484c-4eca-b102-45a7e751e41b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e2d2196-484c-4eca-b102-45a7e751e41b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e2d2196-484c-4eca-b102-45a7e751e41b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89363477-bf64-4690-ba23-d42e48234bf3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89363477-bf64-4690-ba23-d42e48234bf3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89363477-bf64-4690-ba23-d42e48234bf3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2982,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.\",\n          \"It was that loud.Glad to say that the Plantronics 510 maintains a flawless connection to my cell and with no static during normal use.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Y veamos sus primeros registros:\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08bVMp-adI48",
        "outputId": "964ccab8-04af-48ac-9a7e-dc1340a26c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review    10/10\n",
            "label         1\n",
            "Name: 1125, dtype: object\n",
            "\n",
            "\n",
            "review    10/10\n",
            "label         1\n",
            "Name: 1788, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Los dos siguientes comentarios se eliminan con la limpieza posterior a realizar.\n",
        "# Esto debido a que sólo son dos comentarios y no afecta el modelo.\n",
        "\n",
        "print(df.iloc[1125,:])\n",
        "print(\"\\n\")\n",
        "print(df.iloc[1788,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JpOvN3n2Hwe"
      },
      "source": [
        "# Pregunta #2\n",
        "\n",
        "Realiza el proceso de limpieza.\n",
        "\n",
        "Aplica el preprocesamiento que consideres adecuado, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización.\n",
        "\n",
        "Realiza un proceso de limpieza.\n",
        "\n",
        "Aplica el preprocesamiento que consideres adecuado a los comentarios, sin embargo, deberás aplicar necesariamente alguna de las técnicas de lematización,pero no de stemming. Aplica y justifica cualquier otro proceso de limpieza que consideres\n",
        "adecuado.\n",
        "\n",
        "Llamar Xclean a los comentarios procesados y Y a las etiquetas.\n",
        "\n",
        "NOTA: Como aplicaremos modelos embebidos pre-entrenados, queremos palabras lo más cercanas a las existentes en un idioma, inglés en este caso, por ello la técnica de lematización y no de stemming.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHuVRmBz40hW",
        "outputId": "0ec189ef-97a5-4548-973b-7ed9a8cebc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Longitud de mystopwords:  139\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Separar la información\n",
        "#     La \"X\" son los comentarios.\n",
        "#     La \"Y\" son la evaluación.\n",
        "# Ambos, X y Y son \"Series\"\n",
        "\n",
        "X = df.review.copy() # Serie de strings\n",
        "Y = df.label.copy() # Serie de enteros 0s y 1s\n",
        "\n",
        "assert X.shape == (3000,)           # verificando que tenemos la dimensiones esperadas.\n",
        "assert Y.shape == (3000,)\n",
        "\n",
        "# Stopwords\n",
        "negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "mystopwords = set(stopwords.words(\"english\"))\n",
        "mystopwords = [w for w in mystopwords if w not in negwords]\n",
        "print(\"\\n Longitud de mystopwords: \", len(mystopwords))\n",
        "\n",
        "def clean_tok(doc):\n",
        "  assert type(doc) == str\n",
        "\n",
        "  # Cambiar todo a minúsculas\n",
        "    # Justificación:\n",
        "      # Se cambió todo a minúsculas para tomar en cuenta el uso de las mismas palabras y que no afecte el tener mayúsculas o minúsculas.\n",
        "      # De esta manera, se si hay una palabra que tiene minúsculas y la misma palabra pero con una letra en mayúsculas, se toma como si fuera la misma palabra.\n",
        "  tokens = doc.lower()\n",
        "\n",
        "  # Agregar un espacio después de los signos de puntuación\n",
        "    # Justificación:\n",
        "      # Hay oraciones en donde no hay un epacio entre el punto y la siguiente palabra, por lo que toma un token como si fuera una misma,\n",
        "      # cuando en realidad deberían de ser 2 tokens en vez de 1.\n",
        "  tokens = re.sub(r'\\b[\\.]\\b', ' ', tokens)\n",
        "\n",
        "  # Solo considerar caracteres alfabéticos\n",
        "    # Justificación:\n",
        "      # El considerar solo los caracteres alfabéticos nos ayuda a no tomar en cuenta los signos de puntuación o números, ya que en este caso no los necesitamos\n",
        "      # para nuestro análisis. Además nos ayuda a reducir nuestro vocabulario para usar los caracteres que nos ayudan en nuestro análisis, en este caso los alfabéticos.\n",
        "  tokens = re.sub(r'[^a-z\\s]', '  ', tokens)\n",
        "  tokens = re.sub(r'[\\s]{2,}', ' ', tokens)\n",
        "  tokens = tokens.strip()\n",
        "\n",
        "  # Tokenización, longitud mayor a 1, eliminar stopwords y eliminar duplicados\n",
        "     # Justificación:\n",
        "      # Separamos las oraciones por palabras, ya que estas son las que queremos analizar.\n",
        "      # Borramos los stopwords, ya que son palabras que se repiten varias veces y no aportan significado a nuestra oración, como in, the, her, him, he, is etc.\n",
        "      # Al estar hablando de reseñas, no borramos las palabras negativas, ya que nos puede afectar como está escrito un comentario y cambiar su significado.\n",
        "      # Tomamos en cuenta solo las palabras que su longitud sea mayor a 1, ya que este tipo de palabras normalmente no nos dicen mucho, así como I, A, etc.\n",
        "      # Después de hacer el procesamiento anterior, es posible nos queden palabras duplicadas, por lo que las borramos.\n",
        "  tokens = [word for word in tokens.split() if word not in mystopwords]\n",
        "  tokens = list(set([word for word in tokens if len(word) > 1]))\n",
        "\n",
        "  # Sustituir los caracteres que aparecen más de 2 veces a 2 veces\n",
        "    #Justificacion:\n",
        "      # Tomar las palabras que tienen repeticiones de una letra, cuando no debería de tenerla, así como goooooood, es igual que good.\n",
        "      # De esta manera podemos reducir las letras que se repiten para poder tomar estas palabras como la misma y las podamos usar en nuestro análisis.\n",
        "  tokens = [re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", word) for word in tokens]\n",
        "\n",
        "  # Limpieza adicional\n",
        "    #Justificacion:\n",
        "      # En caso dado el patrón anterior no haga match, a continuación el patrón específico para las dos palabras más típicas en reseñas.\n",
        "      # De esta manera podemos reducir las letras que se repiten para poder tomar estas palabras como la misma y las podamos usar en nuestro análisis.\n",
        "  tokens = [re.sub(r\"\\b[g]+[o]{2,}[d]+\\b\", r\"good\", word) for word in tokens]\n",
        "  tokens = [re.sub(r\"\\b[b]+[a]+[d]+\\b\", r\"bad\", word) for word in tokens]\n",
        "\n",
        "  # Usar Lemmatizaion\n",
        "    #Justificación:\n",
        "      # Tenemos variaciones de la misma palabra en el df, por lo que podemos tomar la palabra raíz para tomar estas variaciones como la misma palabra.\n",
        "      # Usamos Lemmatization, ya que usaremos modelos embebidos pre-entrenados más adelante\n",
        "    # Extraer lema o lematización para verbos\n",
        "  tokens = [wnl.lemmatize(word, pos='v') for word in tokens]\n",
        "    # Extraer lema o lematización para sustantivos\n",
        "  tokens = [wnl.lemmatize(word, pos='n') for word in tokens]\n",
        "    # Extraer lema o lematización para adjetivos\n",
        "  tokens = [wnl.lemmatize(word, pos='a') for word in tokens]\n",
        "    # Extraer lema o lematización para adverbios\n",
        "  tokens = [wnl.lemmatize(word, pos='r') for word in tokens]\n",
        "    # Verificar si después del proceso anterior resulta algún stopword\n",
        "  tokens = [word for word in tokens if word not in mystopwords]\n",
        "    # Longitud mayor a 1 y eliminamos palabras duplicadas\n",
        "  tokens = list(set([word for word in tokens if len(word) > 1]))\n",
        "\n",
        "  return tokens\n",
        "\n",
        "# Aplicamos el proceso de limpieza y tokenización:\n",
        "Xclean = [clean_tok(x) for x in X]\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWzvkv0B-lZG",
        "outputId": "0d8f676d-957c-4586-ef00-706be02e56d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no', 'way', 'plug', 'go', 'converter', 'unless']\n",
            "['excellent', 'good', 'case', 'value']\n",
            "['jawbone', 'great']\n",
            "['conversation', 'charger', 'tie', 'major', 'minute', 'problem', 'last']\n",
            "['great', 'mic']\n"
          ]
        }
      ],
      "source": [
        "# Despleguemos los primeros comentarios después de tu proceso de limpieza:\n",
        "\n",
        "for x in Xclean[0:5]:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl7UYWGO2RlJ"
      },
      "source": [
        "# Pregunta #3\n",
        "Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder\n",
        "comparar dichos resultados con los de esta actividad, a saber, 70%, 15% y 15%, para\n",
        "entrenamiento, validación y prueba, respectivamente. Verifica que obtienes 2100 registros de\n",
        "entrenamiento y 450 para cada uno de validación y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be4-V_uX2XTg",
        "outputId": "de9daf00-8af5-4ccd-a337-fa9ddcbea743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ],
      "source": [
        "# ************* Inicia la sección de agregar código:*****************************\n",
        "\n",
        "\n",
        "# Partición de los datos\n",
        "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "# Verificar las formas de los conjuntos de datos\n",
        "assert len(x_train) == 2100\n",
        "assert len(x_val) == 450\n",
        "assert len(x_test) == 450\n",
        "\n",
        "\n",
        "# *********** Termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "print('X,y Train:', len(x_train), len(y_train))\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsfifdcq2XvF"
      },
      "source": [
        "# Pregunta #4\n",
        " Construye tu vocabulario a continuación:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRPikeIk2lAr",
        "outputId": "53132ca6-294b-4ba7-f8a0-0dddf6ecbc9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del diccionario inicial: 3237\n",
            "10 palabras más frecuentes: [('not', 205), ('good', 193), ('great', 134), ('movie', 130), ('phone', 123), ('film', 121), ('work', 109), ('bad', 101), ('time', 99), ('like', 94)]\n"
          ]
        }
      ],
      "source": [
        "# a.    Usa el conjunto de entrenamiento para generar tu vocabulario\n",
        "#     con un tamaño que consideres adecuado:\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "raw_vocab = Counter()\n",
        "\n",
        "for k in range(len(x_train)):\n",
        "  raw_vocab.update(x_train[k])\n",
        "\n",
        "# Mostrar las 10 palabras más frecuentes y el tamaño del vocabulario inicial\n",
        "print(f\"Longitud del diccionario inicial: {len(raw_vocab)}\")\n",
        "print(f\"10 palabras más frecuentes: {raw_vocab.most_common(10)}\")\n",
        "\n",
        "# Definir la frecuencia mínima y longitud mínima\n",
        "  # Justificación:\n",
        "    # Se realizaron pruebas con diferentes frecuencias de palabras, pero la mejor fue con 3, pues a medida que aumentamos, quedan muchos comentarios vacíos.\n",
        "    # Y a medida que se disminuye, agrega ruido al modelo y no se obtiene buenos resultados.\n",
        "    # Respecto a la longitud mínima de la palabra, optamos por 2 debido a que la palabra \"no\" es importante en este contexto y tiene apenas 2 de longitud.\n",
        "min_freq = 3\n",
        "min_length = 2\n",
        "\n",
        "# Filtrar el vocabulario\n",
        "filtered_vocab = {word for word, freq in raw_vocab.items() if freq >= min_freq and len(word) >= min_length}\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJav10-VTIEM",
        "outputId": "119345ea-99d4-4270-a43f-e762ba65e319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del vocabulario generado:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "911"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# b.    Indica el tamaño del vocabulario generado.\n",
        "\n",
        "print('Longitud del vocabulario generado:')\n",
        "\n",
        "\n",
        "# ******* Inicia la sección de agregar código: ***********\n",
        "\n",
        "\n",
        "len(filtered_vocab)\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE9FTyQ_5r4c"
      },
      "source": [
        "c.\t¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        " *  **Generalización:** Usar únicamente el conjunto de entrenamiento asegura que el modelo solo tenga acceso a información que estaría disponible durante el entrenamiento y evita cualquier tipo de información de fuga desde los conjuntos de validación y prueba.\n",
        " *  **Evaluación justa:** Mantener los conjuntos de validación y prueba independientes asegura que estos datos no influencien la creación del vocabulario y permite una evaluación justa y realista del rendimiento del modelo en datos no vistos.\n",
        " *  **Reproducibilidad:** Utilizando solo el conjunto de entrenamiento para construir el vocabulario, se garantiza que el proceso sea repetible y consistente, incluso cuando se cambien los datos de validación y prueba.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WghNGlLkUKrg",
        "outputId": "7d86f800-c0fe-4b96-c071-48277f92fb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X,y Train: 2084 2084\n",
            "X,y Val: 440 440\n",
            "X,y Test 438 438\n",
            "\n",
            "First 5 filtered training examples: [['like', 'star', 'ed', 'good', 'waste', 'much', 'people', 'don'], ['suck', 'special'], ['server', 'pay', 'job', 'tip', 'not', 'bill', 'terrible', 'felt'], ['steak', 'cook', 'understand', 'call', 'don'], ['wrong', 'however', 'sometimes', 'button', 'keypad', 'tinny']]\n",
            "First 5 filtered validation examples: [['battery', 'completely', 'useless'], ['friendly', 'service', 'super'], ['try', 'make', 'call'], ['atmosphere', 'good'], ['turn', 'buy', 'else', 'someone', 'back', 'definitely', 'unless']]\n",
            "First 5 filtered test examples: [['absolutely'], ['plot', 'no', 'first', 'go', 'place', 'keep'], ['time', 'also', 'quick', 'ship'], ['overall'], ['without', 'effect', 'drop']]\n"
          ]
        }
      ],
      "source": [
        "# d.    Con el vocabulario generado, filtra los conjuntos de entrenamiento,\n",
        "#     validación y prueba para que todos los comentarios usen solamente las\n",
        "#     palabras de este vocabulario.\n",
        "\n",
        "#     Llamar train_x, val_x y test_x a estos tres conjuntos.\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Función para filtrar los datos basados en el vocabulario\n",
        "def filter_by_vocab(data, vocab):\n",
        "    return [[word for word in doc if word in vocab] for doc in data]\n",
        "\n",
        "# Filtrar los conjuntos de datos\n",
        "train_x = filter_by_vocab(x_train, filtered_vocab)\n",
        "val_x = filter_by_vocab(x_val, filtered_vocab)\n",
        "test_x = filter_by_vocab(x_test, filtered_vocab)\n",
        "\n",
        "# Filtro para borrar los comentarios vacios\n",
        "def rmv_empty_rev(x_lst, y_series):\n",
        "  df_tmp = pd.DataFrame({'review': [\" \".join(w) for w in x_lst], 'label': y_series})\n",
        "  df_tmp = df_tmp[df_tmp['review'] != \"\"]\n",
        "  x_lst = df_tmp.review\n",
        "  x_lst = [rev.split() for rev in x_lst]\n",
        "  y_series = df_tmp.label\n",
        "\n",
        "  return x_lst, y_series\n",
        "\n",
        "train_x, y_train = rmv_empty_rev(train_x, y_train)\n",
        "val_x, y_val = rmv_empty_rev(val_x, y_val)\n",
        "test_x, y_test = rmv_empty_rev(test_x, y_test)\n",
        "\n",
        "print('X,y Train:', len(train_x), len(y_train))\n",
        "print('X,y Val:', len(val_x), len(y_val))\n",
        "print('X,y Test', len(test_x), len(y_test))\n",
        "\n",
        "# Mostrar algunos ejemplos para verificar\n",
        "print(f\"\\nFirst 5 filtered training examples: {train_x[:5]}\")\n",
        "print(f\"First 5 filtered validation examples: {val_x[:5]}\")\n",
        "print(f\"First 5 filtered test examples: {test_x[:5]}\")\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vklIqGvT2r86"
      },
      "source": [
        "Hasta este punto básicamente has realizado transformaciones muy análogas a las de la semana\n",
        "pasada y que son válidas para muchos de los procesos dentro del análisis de textos.\n",
        "\n",
        "Procedamosahora con los vectores embebidos preentrenados de cada palabra, en lugar de los vectores\n",
        "generados con las matrices Tf-idf que utilizaste la semana pasada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4JD_PFt53kb",
        "outputId": "3ec0630c-5da7-426b-86cd-097302d3fd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['like', 'star', 'ed', 'good', 'waste', 'much', 'people', 'don']\n",
            "['suck', 'special']\n",
            "['server', 'pay', 'job', 'tip', 'not', 'bill', 'terrible', 'felt']\n",
            "['steak', 'cook', 'understand', 'call', 'don']\n",
            "['wrong', 'however', 'sometimes', 'button', 'keypad', 'tinny']\n"
          ]
        }
      ],
      "source": [
        "# Vemos el resultado de los primeros comentarios del conjunto de entrenamiento:\n",
        "\n",
        "for ss in train_x[0:5]:\n",
        "  print(ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrxXhQXj2lg6"
      },
      "source": [
        "# Pregunta #5\n",
        "En particular, utilizaremos los vectores embebidos FastText preentrenados por Facebook.\n",
        "\n",
        "a. Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de Google y Glove de Stanford.\n",
        "\n",
        " Puedes consultar sus páginas correspondientes:\n",
        "\n",
        "https://fasttext.cc/\n",
        "\n",
        "https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "https://nlp.stanford.edu/projects/glove/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u12sIIPbo00"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Embedding</th>\n",
        "    <th>Pros</th>\n",
        "    <th>Cons</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Word2Vec</td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>Captura relaciones semanticas efectivamente</li>\n",
        "        <li>Eficiente para datasets muy grandes</li>\n",
        "        <li>Provee representaciones de palabras significativas</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>Tiende a equivocarse con palabras no ordinarias o raras</li>\n",
        "        <li>Ignora el orden de las palabras</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>GloVe</td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>Efectivo para capturar estadísticas globales del corpus</li>\n",
        "        <li>Bueno para representar relaciones semanticas y sintacticas del corpus</li>\n",
        "        <li>Efectivo para capturar analogias de las palabras</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>Require más memoria para almacenar la matrix co-ocurrencia</li>\n",
        "        <li>Menos efectivo con corpus muy pequeños</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>FastText</td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>Bueno para representar palabras no ordinarias o raras</li>\n",
        "        <li>Capaz de manejar palabras no existentes en el vocabulario</li>\n",
        "        <li>Representacion de palabras enriquecidas debido su descomposición en n-grams</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "    <td>\n",
        "      <ul>\n",
        "        <li>El tamaño del modelo es más grande debido a la información de los n-grams</li>\n",
        "        <li>Periodos de entramiento más largos comparados a Word2Vec</li>\n",
        "      </ul>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yeSmEv20YI"
      },
      "source": [
        "#**Pregunta - 6:**\n",
        "\n",
        "Utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300 para generar un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el “valor” será su vector embebido de dimensión 300.\n",
        "\n",
        "Este diccionario deberá ser del mismo tamaño que el vocabulario previo que hayas construido previamente.\n",
        "\n",
        "Es recomendable que una vez que generes el nuevo vocabulario de vectores embebidos, guardes dicho diccionario en un archivo.\n",
        "\n",
        "Recuerda borrar la variable donde descargaste los 2 millones de vectores embebidos Fasttext.\n",
        "\n",
        "\n",
        "\n",
        "NOTA1: Puedes consultar la documentación: https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "NOTA2: Debido a la cantidad de recursos computacionales que demanda cargar los vectores\n",
        "FastText (son 2 millones de vectores), es recomendable que una vez que generes el nuevo\n",
        "vocabulario de vectores embebidos, guardes dicho diccionario en un archivo (pickle, npz o el que\n",
        "consideres más adecuado). Una vez realizado lo anterior, puedes borrar la variable de FastText\n",
        "para liberar memoria RAM. Apóyense entre los miembros del equipo si alguno de ustedes tiene\n",
        "problemas de recursos computacionales para cargar los vectores embebidos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivlvJcaa3BP6",
        "outputId": "1e18649d-d398-4c3b-e858-3c5294086643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "#Si no se tiene el archivo 'cc.en.300.bin' en la ruta inicial, ejecutar el siguiente comando\n",
        "#y ubicarlo en la ruta \"/content/drive/MyDrive/Colab Notebooks/MNA/Procesamiento de Lenguaje Natural\"\n",
        "\n",
        "#fasttext.util.download_model('en', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "midiccEmb_vector = {}\n",
        "for word in filtered_vocab:\n",
        "  tmp = ft.get_word_vector(word)\n",
        "  midiccEmb_vector.update({word: tmp})\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SceCwt6a3BrI"
      },
      "source": [
        "# Pregunta #7\n",
        "\n",
        "Generamos los vectores embebidos a paertir de los conjuntos de entrenamiento, validación y preuba.\n",
        "\n",
        "Los llamaremos trainEmb, valEmb y testEmb, respectivamente.\n",
        "Una manera de utilizar los vectores embebidos con modelos de aprendizaje automático (machine learning) en documentos de texto, es asignar a cada comentario el vector embebido de dimensión predeterminada que resulta de promediar todos los vectores embebidos de cada una de sus palabras (tokens).\n",
        "\n",
        "Así, en este ejercicio deberás generar los conjuntos de entrenamiento, validación y prueba de de esta manera. Los llamaremos trainEmb, valEmb y testEmb, respectivamente. Es decir, ahora cada comentario es un solo comentario de dimensión 300."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md8YU1NS6slS"
      },
      "outputs": [],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "trainEmb = np.array([np.mean(np.array([midiccEmb_vector[word] for word in sent]), axis=0) for sent in train_x])\n",
        "valEmb = np.array([np.mean(np.array([midiccEmb_vector[word] for word in sent]), axis=0) for sent in val_x])\n",
        "testEmb = np.array([np.mean(np.array([midiccEmb_vector[word] for word in sent]), axis=0) for sent in test_x])\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY6gyuqzW1nq",
        "outputId": "b3aacf16-6100-4f03-bd22-bbe460d85abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-Emb: (2084, 300)\n",
            "Val-Emb: (440, 300)\n",
            "Test-Emb: (438, 300)\n"
          ]
        }
      ],
      "source": [
        "# Veamos las dimensiones de cada conjunto embebido:\n",
        "print(\"Train-Emb:\", trainEmb.shape)\n",
        "print(\"Val-Emb:\", valEmb.shape)\n",
        "print(\"Test-Emb:\", testEmb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzeJkZFw3KWx"
      },
      "source": [
        "# Pregunta #8\n",
        "\n",
        "Utiliza los modelos de regresión logística y bosque aleatorio (random forest) y encuentra sus desempeños.\n",
        "\n",
        "Compara los resultados con los de la semana anterior.\n",
        "\n",
        "\n",
        "Utilizando los nuevos conjuntos embebidos de entrenamiento y validación, obtener los modelos de\n",
        "regresión logística y bosque aleatorio (random forest). Para cada modelo muestra el valor de la\n",
        "exactitud (accuracy) y el reporte de sklearn dado por la función classification_report(). Verifica que\n",
        "no estén sobreentrenados y compara tus resultados con los que obtuviste en la actividad de la\n",
        "semana pasada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNOBThJQM28L",
        "outputId": "f9b72dd7-d37e-4076-b0c2-4a474c7ce53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: Train-accuracy: 86.18%\n",
            "LR: Val-accuracy: 84%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       211\n",
            "           1       0.85      0.83      0.84       229\n",
            "\n",
            "    accuracy                           0.84       440\n",
            "   macro avg       0.84      0.84      0.84       440\n",
            "weighted avg       0.84      0.84      0.84       440\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# REGRESIÓN LOGÍSTICA:\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "# Inicializamos el modelo de LR\n",
        "modeloLR = LogisticRegression(C=11, max_iter=1000)\n",
        "# Entrenamos con los datos de entrenamiento DTM\n",
        "modeloLR.fit(trainEmb, y_train)\n",
        "# Realizamos las predicciones con los datos de validación transformados\n",
        "yhat = modeloLR.predict(valEmb)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloLR.score(trainEmb, y_train)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloLR.score(valEmb, y_val)))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_val, yhat, zero_division=0))\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mivHKyfgN_Ez",
        "outputId": "0fb2996e-655e-4bb9-f6f9-6cbce2005f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RF: Train-accuracy: 79.89%\n",
            "RF: Val-accuracy: 76.82%\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       211\n",
            "           1       0.81      0.72      0.76       229\n",
            "\n",
            "    accuracy                           0.77       440\n",
            "   macro avg       0.77      0.77      0.77       440\n",
            "weighted avg       0.77      0.77      0.77       440\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# BOSQUE ALEATORIO (Random Forest):\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "# Inicializamos el modelo de RF\n",
        "modeloRF = RandomForestClassifier(n_estimators = 69,\n",
        "                                  max_depth=2,\n",
        "                                  bootstrap=True,\n",
        "                                  random_state=11,\n",
        "                                  min_samples_split = 2,\n",
        "                                  min_samples_leaf = 111,\n",
        "                                  max_features ='sqrt'\n",
        "                                  )\n",
        "# Entrenamos con los datos de entrenamiento DTM\n",
        "modeloRF.fit(trainEmb, y_train)\n",
        "# Realizamos las predicciones con los datos de validación transformados\n",
        "yhat = modeloRF.predict(valEmb)\n",
        "\n",
        "print('\\nRF: Train-accuracy: %.2f%%' % (100*modeloRF.score(trainEmb, y_train)))\n",
        "print('RF: Val-accuracy: %.2f%%' % (100*modeloRF.score(valEmb, y_val)))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_val, yhat, zero_division=0))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FXaAdUl7W83"
      },
      "source": [
        "> Como regla general, se busca que la diferencia entre la precisión en entrenamiento y validación sea lo más pequeña posible. En este caso, dado el tamaño del conjunto de datos, la complejidad del modelo y la naturaleza del problema, definimos esa diferencia máxima de 3% para que no se considere sobreentrenamiento. En particular, en los dos modelos usados anteriormente, la diferencia es menos del 3%, por lo que descartamos sobreentrenamiento.\n",
        "\n",
        "> En comparación con los resultados de la semana pasada, esta semana se obtienen valores ligeramente superiores. Sin embargo, se esperaban resultados más altos en comparación con las matrices de conteo y tf-idf dado a que FastText es un modelo pre-entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVLYbnHJ3P2i"
      },
      "source": [
        "# Pregunta #9\n",
        "Con el mejor modelo y el nuevo conjunto de prueba, obtener la mejor matriz de confusión y el\n",
        "classification_report() de sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNoJV5Ia3UxF",
        "outputId": "05e44ce6-cf96-4be1-c9b8-4956492cae55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-accuracy con el mejor modelo 82.88%\n",
            "\n",
            "Matriz de confusión con el mejor modelo:\n",
            "[[175  33]\n",
            " [ 42 188]]\n",
            "\n",
            "Matriz de confusión con el mejor modelo en proporciones:\n",
            "[[0.39954338 0.07534247]\n",
            " [0.09589041 0.42922374]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.82       208\n",
            "           1       0.85      0.82      0.83       230\n",
            "\n",
            "    accuracy                           0.83       438\n",
            "   macro avg       0.83      0.83      0.83       438\n",
            "weighted avg       0.83      0.83      0.83       438\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "mejor_modelo = modeloLR\n",
        "\n",
        "print('Test-accuracy con el mejor modelo %.2f%%' % (100*mejor_modelo.score(testEmb, y_test)))\n",
        "\n",
        "pred = mejor_modelo.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
        "\n",
        "print('\\nMatriz de confusión con el mejor modelo en proporciones:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test, pred, zero_division=0))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iAg1a2q3VKe"
      },
      "source": [
        "# Pregunta #10\n",
        "Incluye tus comentarios finales de la actividad.\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "En este notebook, implementamos y comparamos dos modelos de aprendizaje automático para la clasificación de textos: Regresión Logística (LR) y Bosques Aleatorios (RF). La metodología incluyó varios pasos clave, como la preprocesamiento de datos, la generación de embeddings usando FastText, el entrenamiento de modelos y la evaluación del rendimiento.\n",
        "\n",
        "Primero, preprocesamos los datos de texto limpiándolos y tokenizándolos, y luego generamos embeddings de palabras con el modelo preentrenado FastText. Esto nos permitió utilizar vectores de características ricos y de alta dimensión para cada palabra, capturando tanto información sintáctica como semántica.\n",
        "\n",
        "Luego, entrenamos los modelos de Regresión Logística y Bosques Aleatorios usando estos embeddings. Para la Regresión Logística, observamos una precisión de entrenamiento del 86.18% y una precisión de validación del 84%, con precisión, recall y F1-score relativamente equilibrados en ambas clases. El modelo de Bosques Aleatorios logró precisiones de entrenamiento y validación ligeramente más bajas del 79.89% y 76.82%, respectivamente.\n",
        "\n",
        "Comparando los dos modelos, la Regresión Logística mostró métricas de rendimiento ligeramente mejores. Su mayor precisión y métricas de precisión, recall y F1-score más equilibradas sugieren que es mejor para generalizar a datos no vistos en comparación con el modelo de Bosques Aleatorios. Además, el modelo de Regresión Logística mostró un sobreajuste mínimo, indicado por la pequeña diferencia entre las precisiones de entrenamiento y validación. Finalmente, el modelo de Regresión Logística evaluado en el conjunto de entrenamiento, logró un satisfactorio 82.88% de precisión, lo cual indica una ligera mejoría respecto a la actividad de la semana pasada.\n",
        "\n",
        "En general, se presume que entre más bajo es min_freq se introduce más ruido al modelo, lo que hace que la precisión no sea la mejor, es decir, el modelo no aprende a generalizar cuando se evalua con el set de pruebas, pues no se obtienen buenos resultados. Sin embargo, cuando se toman valores de más de 5 en min_freq, se obtiene una gran cantidad de comentarios vacíos en el conjunto de entrenamiento, lo cual deteriora el desempeño del modelo. La disparidad entre los valores de Falsos Negativos y Falsos Positivos se debe principalmente a la falta de contextualización en los métodos utilizados para generar las representaciones vectoriales de las palabras en los comentarios. Adicional, dependiendo del orden y los pasos de la limpieza llevado a cabo en los primeros puntos, el desempeño del modelo mejora o empeora, por lo que es fundamental concentrarse en el pre-procesamiento.\n",
        "\n",
        "\n",
        "En conclusión, la metodología de usar embeddings de FastText proporcionó una base sólida para ambos modelos, pero el modelo de Regresión Logística resultó ser la mejor opción para esta tarea de clasificación de textos. Su capacidad para generalizar bien, combinada con métricas de rendimiento consistentes, lo convierte en un modelo más fiable para aplicaciones futuras. Este análisis comparativo destaca la importancia de evaluar múltiples modelos y metodologías para identificar el enfoque más efectivo para un problema dado, es decir hacer mucho testing.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7e-esq_3Z2l"
      },
      "source": [
        "##**Fin de la Actividad de vectores Embebidos - FastText**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
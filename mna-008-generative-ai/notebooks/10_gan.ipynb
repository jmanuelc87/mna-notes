{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q pillow\n",
    "# %pip install -q numpy\n",
    "# %pip install -q scipy\n",
    "# %pip install -q matplotlib\n",
    "# %pip install -q torchinfo\n",
    "# %pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    if device.type == \"cuda\":\n",
    "        # Allow TensorFloat32 on matmul and convolutions\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "print(f\"Available device: {device.type}\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_fn = v2.Compose(\n",
    "    [\n",
    "        v2.Resize((28, 28)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "postprocess_fn = v2.Compose(\n",
    "    [\n",
    "        v2.ToPILImage(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../datasets\"\n",
    "NUM_TRAIN = 60000\n",
    "NUM_VAL = 5000\n",
    "NUM_TEST = 5000\n",
    "MINIBATCH_SIZE = 96\n",
    "EPOCHS = 20\n",
    "\n",
    "fashion_train = datasets.FashionMNIST(\n",
    "    DATA_PATH, train=True, download=True, transform=preprocess_fn\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    fashion_train,\n",
    "    batch_size=MINIBATCH_SIZE,\n",
    "    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)),\n",
    ")\n",
    "\n",
    "len(fashion_train), len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Linear Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrimator_train_step(model, real_data, fake_data, loss_fn, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    real_pred = model(real_data)\n",
    "\n",
    "    real_error = loss_fn(real_pred, torch.ones(len(real_data), 1).to(device))\n",
    "    real_error.backward()\n",
    "\n",
    "    fake_pred = model(fake_data)\n",
    "\n",
    "    fake_error = loss_fn(fake_pred, torch.zeros(len(fake_data), 1).to(device))\n",
    "    fake_error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return real_error + fake_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(model, fake_data, real_data, loss_fn, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prediction = model(fake_data)\n",
    "    error = loss_fn(prediction, torch.ones(len(real_data), 1).to(device))\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=2e-4)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discrimator, dataloader, epochs=200):\n",
    "    d_scheduler = lr_scheduler.LinearLR(\n",
    "        d_optimizer, start_factor=0.99, end_factor=0.66, total_iters=17\n",
    "    )\n",
    "\n",
    "    g_scheduler = lr_scheduler.LinearLR(\n",
    "        g_optimizer, start_factor=0.99, end_factor=0.66, total_iters=17\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_a = torch.zeros(2, len(dataloader))\n",
    "        for i, (images, _) in enumerate(tqdm(dataloader)):\n",
    "            \n",
    "            real_data = images.view(len(images), -1).to(device)\n",
    "            \n",
    "            noise = torch.randn(len(real_data), 100)\n",
    "            \n",
    "            fake_data = generator(noise).to(device)\n",
    "            fake_data = fake_data.detach()\n",
    "\n",
    "            d_loss = discrimator_train_step(\n",
    "                discrimator, real_data, fake_data, loss, d_optimizer\n",
    "            )\n",
    "\n",
    "            noise = torch.randn(len(real_data), 100)\n",
    "            fake_data = generator(noise).to(device)\n",
    "\n",
    "            g_loss = generator_train_step(\n",
    "                discrimator, fake_data, real_data, loss, g_optimizer\n",
    "            )\n",
    "\n",
    "            loss_a[0][i] = d_loss\n",
    "            loss_a[1][i] = g_loss\n",
    "            \n",
    "        d_scheduler.step()\n",
    "        g_scheduler.step()\n",
    "\n",
    "        print(\n",
    "            f\"epoch={epoch + 1} d_loss={loss_a[0].mean().item():.4f} g_loss={loss_a[1].mean().item():.4f} d_lr={d_optimizer.param_groups[0]['lr']:.7f} g_lr={g_optimizer.param_groups[0]['lr']:.7f}\",\n",
    "            end=\"\\n\\n\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator, discriminator, train_dataloader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    image = image.squeeze(0)  # remove the fake batch dimension\n",
    "    image = postprocess_fn(image)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "z = torch.randn(64, 100).to(device)\n",
    "sample_images = generator(z).data.cpu().view(64, 1, 28, 28)\n",
    "\n",
    "grid = make_grid(sample_images, nrow=8, normalize=True)\n",
    "\n",
    "imshow(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Convolutional Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_fn = v2.Compose(\n",
    "    [\n",
    "        v2.Resize((64, 64)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "postprocess_fn = v2.Compose(\n",
    "    [\n",
    "        v2.ToPILImage(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ConvDiscriminator(), input_size=(96, 1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 64 * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ConvGenerator(), input_size=(96, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_discriminator = ConvDiscriminator().to(device)\n",
    "conv_generator = ConvGenerator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "\n",
    "d_optimizer = torch.optim.Adam(\n",
    "    conv_discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999)\n",
    ")\n",
    "g_optimizer = torch.optim.Adam(conv_generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrimator_train_step(model, real_data, fake_data, loss_fn, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    real_pred = model(real_data)\n",
    "\n",
    "    real_error = loss_fn(real_pred.squeeze(), torch.ones(len(real_data)).to(device))\n",
    "    real_error.backward()\n",
    "\n",
    "    fake_pred = model(fake_data)\n",
    "\n",
    "    fake_error = loss_fn(fake_pred.squeeze(), torch.zeros(len(fake_data)).to(device))\n",
    "    fake_error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return real_error + fake_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(model, fake_data, real_data, loss_fn, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prediction = model(fake_data)\n",
    "    error = loss_fn(prediction.squeeze(), torch.ones(len(real_data)).to(device))\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_train(generator, discrimator, dataloader, epochs=200):\n",
    "    for epoch in range(epochs):\n",
    "        loss_a = torch.zeros(2, len(dataloader))\n",
    "        for i, (images, _) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "            real_data = images.to(device)\n",
    "\n",
    "            noise = torch.randn(len(real_data), 1, 1, 1).to(device)\n",
    "\n",
    "            fake_data = generator(noise).to(device)\n",
    "            fake_data = fake_data.detach()\n",
    "\n",
    "            d_loss = discrimator_train_step(\n",
    "                discrimator, real_data, fake_data, loss, d_optimizer\n",
    "            )\n",
    "\n",
    "            noise = torch.randn(len(real_data), 1, 1, 1)\n",
    "            fake_data = generator(noise).to(device)\n",
    "\n",
    "            g_loss = generator_train_step(\n",
    "                discrimator, fake_data, real_data, loss, g_optimizer\n",
    "            )\n",
    "\n",
    "            loss_a[0][i] = d_loss\n",
    "            loss_a[1][i] = g_loss\n",
    "\n",
    "        print(\n",
    "            f\"epoch={epoch + 1} d_loss={loss_a[0].mean().item():.4f} g_loss={loss_a[1].mean().item():.4f}\",\n",
    "            end=\"\\n\\n\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_train(conv_generator, conv_discriminator, train_dataloader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_generator.eval()\n",
    "z = torch.randn(64, 1, 1, 1).to(device)\n",
    "sample_images = conv_generator(z).detach().cpu()\n",
    "\n",
    "grid = make_grid(sample_images, nrow=8, normalize=True)\n",
    "\n",
    "imshow(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
